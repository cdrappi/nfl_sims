{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import nfl_data_py\n",
                "import math\n",
                "import os\n",
                "from typing import List\n",
                "from sklearn.linear_model import LogisticRegression, Ridge, PoissonRegressor\n",
                "\n",
                "from pbp.data import (\n",
                "    CURRENT_SEASON,\n",
                "    BASELINES_PATH,\n",
                "    MODELS_PATH,\n",
                "    LOGR_KWARGS,\n",
                "    POIS_KWARGS,\n",
                "    state_features,\n",
                "    add_clock_stops,\n",
                "    add_playcall_features,\n",
                "    load_pbp_data,\n",
                "    make_penalty_zs,\n",
                "    make_proe_data,\n",
                ")\n",
                "\n",
                "pd.set_option('display.max_rows', None)\n",
                "pd.set_option('display.max_columns', None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEASONS = list(range(2017, CURRENT_SEASON + 1))\n",
                "\n",
                "YARDS_PER_DESIGNED_RUN = 4.25\n",
                "YARDS_PER_SCRAMBLE = 7.35\n",
                "RUSHING_EPSILON = 0.01"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CARRY_ELIGIBLE_POSITIONS = {'QB','RB','FB','WR','TE'}\n",
                "this_season_rosters = nfl_data_py.import_seasonal_rosters(years=[CURRENT_SEASON])\n",
                "rosters = (\n",
                "    this_season_rosters[this_season_rosters['position'].isin(CARRY_ELIGIBLE_POSITIONS)]\n",
                "    .rename(columns={'player_id': 'rusher_id'})\n",
                ")\n",
                "\n",
                "players = nfl_data_py.import_players()\n",
                "rusher_names = players[['gsis_id','display_name','position']].rename(columns={'gsis_id': 'rusher_id', 'display_name': 'name'})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    pbp.head(1)\n",
                "except:\n",
                "    pbp_copy = load_pbp_data(SEASONS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pbp = pbp_copy.copy()\n",
                "\n",
                "drive_keys = ['game_id','drive','posteam','defteam', 'posteam_score', 'defteam_score']\n",
                "drive_teams = (\n",
                "    pbp[~pbp['posteam'].isna() & ~pbp['defteam'].isna() & ~pbp['posteam_score'].isna() & ~pbp['defteam_score'].isna()]\n",
                "    [drive_keys]\n",
                "    .groupby(drive_keys, as_index=False)\n",
                "    .nth(0)\n",
                "    .rename(columns={'posteam': 'drive_offense', 'defteam': 'drive_defense', 'posteam_score': 'off_score', 'defteam_score': 'def_score'})\n",
                ")\n",
                "pbp['playcall'] = ''\n",
                "pbp = pbp.merge(drive_teams, on=['game_id', 'drive'], how='left').drop_duplicates(subset=['play_id','game_id'])\n",
                "\n",
                "pbp.loc[pbp['off_score'].isna(), 'off_score'] = pbp['posteam_score']\n",
                "pbp.loc[pbp['def_score'].isna(), 'def_score'] = pbp['defteam_score']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(offense_proes, defense_proes, offense_rz_proes, defense_rz_proes) = make_proe_data(pbp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "DESIGNED RUSH OUTCOMES\n",
                "\n",
                "'fumble_lost' = 1\n",
                "    'return_touchdown' = 1\n",
                "'safety' = 1\n",
                "'rush_touchdown' = 1\n",
                "\n",
                "'yards_gained' (non-everything else)\n",
                "\"\"\"\n",
                "offensive_penalty = pbp['penalty_team'] == pbp['posteam']\n",
                "defensive_penalty = pbp['penalty_team'] == pbp['defteam']\n",
                "\n",
                "designed_runs = (\n",
                "    (\n",
                "        (pbp['play_type'] == 'run')\n",
                "        & (pbp['qb_scramble'] == 0)\n",
                "        & (pbp['qb_kneel'] == 0)\n",
                "        & (pbp['two_point_attempt'] == 0)\n",
                "    )\n",
                ")\n",
                "\n",
                "# designed run & sub-outcomes\n",
                "pbp.loc[designed_runs, 'playcall'] = 'DESIGNED_RUN'\n",
                "\n",
                "pbp['designed_run'] = ''\n",
                "pbp.loc[designed_runs, 'designed_run'] = 'YARDS'\n",
                "pbp.loc[designed_runs & (pbp['penalty'] == 1) & offensive_penalty, 'designed_run'] = 'OFFENSIVE_PENALTY'\n",
                "pbp.loc[designed_runs & (pbp['penalty'] == 1) & defensive_penalty, 'designed_run'] = 'DEFENSIVE_PENALTY'\n",
                "pbp.loc[designed_runs & (pbp['fumble_lost'] == 1), 'designed_run'] = 'FUMBLE_LOST'\n",
                "pbp.loc[designed_runs & (pbp['rush_touchdown'] == 1), 'designed_run'] = 'RUSHING_TD'\n",
                "pbp.loc[designed_runs & (pbp['safety'] == 1), 'designed_run'] = 'SAFETY'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pbp['home_timeout'] = 0\n",
                "pbp['away_timeout'] = 0\n",
                "\n",
                "pbp.loc[pbp['timeout'] == 'OFFENSIVE_TIMEOUT', 'home_timeout'] = (pbp['drive_offense'] == pbp['home_team']).astype(int)\n",
                "pbp.loc[pbp['timeout'] == 'DEFENSIVE_TIMEOUT', 'home_timeout'] = (pbp['drive_defense'] == pbp['home_team']).astype(int)\n",
                "\n",
                "pbp.loc[pbp['timeout'] == 'OFFENSIVE_TIMEOUT', 'away_timeout'] = (pbp['drive_offense'] == pbp['away_team']).astype(int)\n",
                "pbp.loc[pbp['timeout'] == 'DEFENSIVE_TIMEOUT', 'away_timeout'] = (pbp['drive_defense'] == pbp['away_team']).astype(int)\n",
                "\n",
                "pbp['home_timeout_prev'] = pbp['home_timeout'].shift(1)\n",
                "pbp['away_timeout_prev'] = pbp['away_timeout'].shift(1)\n",
                "pbp['duplicate_timeout'] = (\n",
                "    ((pbp['home_timeout_prev'] == 1) & (pbp['home_timeout'] == 1))\n",
                "    | ((pbp['away_timeout_prev'] == 1) & (pbp['away_timeout'] == 1))\n",
                ")\n",
                "pbp.loc[pbp['home_timeout_prev'] == 1, 'home_timeout'] = 0\n",
                "pbp.loc[pbp['away_timeout_prev'] == 1, 'away_timeout'] = 0\n",
                "\n",
                "pbp.loc[pbp['duplicate_timeout'], 'timeout'] = 'DUPLICATE'\n",
                "pbp.loc[pbp['duplicate_timeout'], 'playcall'] = 'DUPLICATE_TIMEOUT'\n",
                "\n",
                "pbp['total_home_timeouts'] = pbp.groupby(['game_id','home_team', 'game_half'])['home_timeout'].cumsum()\n",
                "pbp['total_away_timeouts'] = pbp.groupby(['game_id','away_team', 'game_half'])['away_timeout'].cumsum()\n",
                "\n",
                "\n",
                "pbp['off_timeouts_left'] = 3\n",
                "pbp['def_timeouts_left'] = 3\n",
                "\n",
                "pbp.loc[pbp['drive_offense'] == pbp['home_team'], 'off_timeouts_left'] = 3 - pbp['total_home_timeouts']\n",
                "pbp.loc[pbp['drive_offense'] == pbp['away_team'], 'off_timeouts_left'] = 3 - pbp['total_away_timeouts']\n",
                "\n",
                "pbp.loc[pbp['drive_defense'] == pbp['home_team'], 'def_timeouts_left'] = 3 - pbp['total_home_timeouts']\n",
                "pbp.loc[pbp['drive_defense'] == pbp['away_team'], 'def_timeouts_left'] = 3 - pbp['total_away_timeouts']\n",
                "\n",
                "pbp['off_timeouts_remaining'] = pbp['posteam_timeouts_remaining'].combine_first(pbp['off_timeouts_left']).astype(int).clip(0, 3)\n",
                "pbp['def_timeouts_remaining'] = pbp['defteam_timeouts_remaining'].combine_first(pbp['def_timeouts_left']).astype(int).clip(0, 3)\n",
                "\n",
                "pbp['down'] = pbp['down'].apply(lambda x: str(int(x)) if not math.isnan(x) else None)\n",
                "pbp['qtr'] = pbp['qtr'].apply(lambda x: str(int(x)) if not math.isnan(x) else None)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pbp['timeout'] = 'PLAY'\n",
                "for cat in ['NEUTRAL_TIMEOUT', 'DEFENSIVE_TIMEOUT', 'OFFENSIVE_TIMEOUT']:\n",
                "    pbp.loc[pbp['playcall'] == cat, 'timeout'] = cat"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "add_clock_stops(pbp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "responses = [\n",
                "    'timeout',\n",
                "    'rushing_yards',\n",
                "    'rush_touchdown',\n",
                "    'return_touchdown',\n",
                "    'playcall',\n",
                "    'designed_run',\n",
                "    'play_type',\n",
                "    # other\n",
                "    'extra_point_attempt',\n",
                "    'two_point_attempt',\n",
                "    'penalty_team',\n",
                "    'rusher_id',\n",
                "    'passer_id',\n",
                "    'clock_runs_after',\n",
                "    'safety',\n",
                "    'fumble_lost',\n",
                "    'location',\n",
                "]\n",
                "\n",
                "raw_features = [\n",
                "    'down',\n",
                "    'ydstogo',\n",
                "    'goal_to_go',\n",
                "    'qtr', \n",
                "    'clock_running',\n",
                "    # 'quarter_seconds_remaining',\n",
                "    'yardline_100',\n",
                "    'off_score',\n",
                "    'def_score',\n",
                "    # 'play_clock',\n",
                "    'game_seconds_remaining',\n",
                "    'half_seconds_remaining',\n",
                "    # 'wp', \n",
                "    'qb_scramble',\n",
                "    'off_timeouts_remaining',\n",
                "    'def_timeouts_remaining',\n",
                "    # 'total', 'spread_line',\n",
                "]\n",
                "\n",
                "cols = responses + ['posteam', 'defteam', 'season', 'home_team'] + raw_features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "off_penalties, def_penalties = make_penalty_zs(pbp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = (\n",
                "    pd.get_dummies(pbp[cols], columns=['down', 'qtr', 'off_timeouts_remaining', 'def_timeouts_remaining'])\n",
                "    .merge(offense_proes, how='left', on=['posteam','season'])\n",
                "    .merge(defense_proes, how='left', on=['defteam','season'])\n",
                "    .merge(offense_rz_proes, how='left', on=['posteam','season'])\n",
                "    .merge(defense_rz_proes, how='left', on=['defteam','season'])\n",
                "    .merge(off_penalties, how='left', on=['posteam','season'])\n",
                "    .merge(def_penalties, how='left', on=['defteam','season'])   \n",
                ")\n",
                "\n",
                "dataset.loc[dataset['rusher_id'].isna(), 'rusher_id'] = dataset['passer_id']\n",
                "add_playcall_features(dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "common_timeout_features = [\n",
                "    'clock_running',\n",
                "    'possdiff_per_minute',\n",
                "    'fgpossdiff_per_minute',\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "is_down = (dataset['down_1'] + dataset['down_2'] + dataset['down_3'] + dataset['down_4']) == 1\n",
                "runs_df = (\n",
                "    dataset[(dataset['playcall'] == 'DESIGNED_RUN') | (dataset['qb_scramble'] == 1) & is_down & (dataset['play_type'] != 'no_play')]\n",
                "    [['playcall','play_type','posteam','defteam','season','qb_scramble','rushing_yards','rusher_id','rush_touchdown','return_touchdown','clock_runs_after','safety', 'fumble_lost','ydstogo','yardline_100'] + state_features + common_timeout_features]\n",
                "    .dropna()\n",
                ")\n",
                "\n",
                "runs_df['off_season'] = runs_df['posteam'] + '_' + runs_df['season'].astype(str)\n",
                "runs_df['def_season'] = runs_df['defteam'] + '_' + runs_df['season'].astype(str)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def unpack_line(f):\n",
                "    side, team, season = f.split('_')\n",
                "    return {'side': side, 'team': team, 'season': int(season)}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_line_coefs = []\n",
                "for season in SEASONS:\n",
                "    season_df = runs_df[(runs_df['season'] == season) & (runs_df['qb_scramble'] == 0)].reset_index(drop=True)\n",
                "    offenses = pd.get_dummies(season_df['off_season'], prefix='off')\n",
                "    # rushing yards is good for offense but bad for defense\n",
                "    defenses = -1 * pd.get_dummies(season_df['def_season'], prefix='def')\n",
                "    season_df[offenses.columns] = offenses\n",
                "    season_df[defenses.columns] = defenses\n",
                "\n",
                "    line_features = list(offenses.columns) + list(defenses.columns)\n",
                "    line_models = Ridge(**POIS_KWARGS)\n",
                "    line_models.fit(season_df[line_features], season_df['rushing_yards'])\n",
                "    line_coefs = [\n",
                "        {'coef': c, **unpack_line(f)}\n",
                "        for f, c in zip(line_features, line_models.coef_)\n",
                "    ]\n",
                "    all_line_coefs.extend(line_coefs)\n",
                "line_coefs_df = pd.DataFrame(all_line_coefs)\n",
                "line_coefs_df['line_z'] = (line_coefs_df['coef'] - line_coefs_df['coef'].mean()) / line_coefs_df['coef'].std()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "line_cols = ['team','season','line_z']\n",
                "rushing_skills = (\n",
                "    runs_df\n",
                "    .merge(\n",
                "        line_coefs_df[line_coefs_df['side'] == 'off'][line_cols].rename(columns={'line_z': 'ol_z'}),\n",
                "        how='left',\n",
                "        left_on=['season','posteam'],\n",
                "        right_on=['season','team']\n",
                "    ).merge(\n",
                "        line_coefs_df[line_coefs_df['side'] == 'def'][line_cols].rename(columns={'line_z': 'dl_z'}),\n",
                "        how='left',\n",
                "        left_on=['season','defteam'],\n",
                "        right_on=['season','team']\n",
                "    )\n",
                "    .dropna()\n",
                ")\n",
                "\n",
                "rushing_skills['ol_dl_z'] = rushing_skills['ol_z'] * rushing_skills['dl_z']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rushing_exp_features = [\n",
                "    *state_features,\n",
                "    *common_timeout_features,\n",
                "    'ol_z',\n",
                "    'dl_z',\n",
                "    'ol_dl_z',\n",
                "]\n",
                "\n",
                "is_scramble = rushing_skills['qb_scramble'] == 1\n",
                "designed_rush_df = rushing_skills[~is_scramble].reset_index(drop=True)\n",
                "scramble_df = rushing_skills[is_scramble].reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rushing_exp_model = Ridge(**POIS_KWARGS)\n",
                "rushing_exp_model.fit(designed_rush_df[rushing_exp_features], designed_rush_df['rushing_yards'])\n",
                "designed_rush_df['exp_rushing_yards'] = rushing_exp_model.predict(designed_rush_df[rushing_exp_features])\n",
                "designed_rush_df['ryoe'] = designed_rush_df['rushing_yards'] - designed_rush_df['exp_rushing_yards']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scramble_exp_model = Ridge(**POIS_KWARGS)\n",
                "scramble_exp_model.fit(scramble_df[rushing_exp_features], scramble_df['rushing_yards'])\n",
                "scramble_df['exp_rushing_yards'] = scramble_exp_model.predict(scramble_df[rushing_exp_features])\n",
                "scramble_df['syoe'] = scramble_df['rushing_yards'] - scramble_df['exp_rushing_yards']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_fake_data(df_: pd.DataFrame, col: str) -> pd.DataFrame:\n",
                "    quantiles = [i/50 for i in range(1,50)]\n",
                "    ryoe_quantiles = df_[col].quantile(q=quantiles)\n",
                "    distinct_rushers = df_[['season','rusher_id']].drop_duplicates()\n",
                "    fake_data = pd.DataFrame([\n",
                "        {\n",
                "            'season': dr['season'],\n",
                "            'rusher_id': dr['rusher_id'],\n",
                "            'yoe': ryoe, \n",
                "        }\n",
                "        for dr in distinct_rushers.to_dict(orient='records')\n",
                "        for ryoe in ryoe_quantiles\n",
                "    ])\n",
                "    ryoe_regressed = pd.concat([df_.rename(columns={col: 'yoe'})[['season','rusher_id','yoe']], fake_data])\n",
                "    ryoe_regressed['count'] = 1\n",
                "    ryoe_df = (\n",
                "        ryoe_regressed\n",
                "        .groupby(['season','rusher_id'], as_index=False)\n",
                "        .aggregate({'yoe': ['mean', 'std'], 'count': 'count'})\n",
                "        .sort_values(('yoe', 'mean'), ascending=False)\n",
                "    )\n",
                "    ryoe_df.columns = ['_'.join(col).strip() if col[0] == 'yoe' in col else col[0] for col in ryoe_df.columns.values]\n",
                "    return ryoe_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ryoe_df = add_fake_data(designed_rush_df, 'ryoe')\n",
                "syoe_df = add_fake_data(scramble_df, 'syoe')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ryoe_df.merge(rusher_names, how='left', on='rusher_id').head(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "syoe_df.merge(rusher_names, how='left', on='rusher_id').head(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def scramble_rate_season_weight(season: int) -> float:\n",
                "    return math.exp(1.0 * (season - CURRENT_SEASON))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "possible_scrambles = (dataset['play_type'] == 'pass') | (dataset['qb_scramble'] == 1)\n",
                "scramble_rate_df = dataset[possible_scrambles].reset_index(drop=True)\n",
                "\n",
                "PRIOR_DROPBACKS = 10\n",
                "mean_scramble_rate = scramble_rate_df['qb_scramble'].mean()\n",
                "\n",
                "scramble_rate_df.loc[scramble_rate_df['passer_id'].isna(), 'passer_id'] = scramble_rate_df['rusher_id']\n",
                "scramble_rate_df['rusher_id'] = scramble_rate_df['passer_id']\n",
                "scramble_rate_df['count'] = 1\n",
                "scramble_rate_df.dropna(subset=['rusher_id'], inplace=True)\n",
                "\n",
                "scramble_rates = (\n",
                "    scramble_rate_df\n",
                "    .groupby(['season','rusher_id'], as_index=False)\n",
                "    .aggregate({'qb_scramble': 'mean', 'count': 'count'})\n",
                ")\n",
                "scramble_rates['regr_scramble_rate'] = (scramble_rates['count'] * scramble_rates['qb_scramble'] + PRIOR_DROPBACKS * mean_scramble_rate) / (scramble_rates['count'] + PRIOR_DROPBACKS)\n",
                "scramble_rates.sort_values('regr_scramble_rate', ascending=False, inplace=True)\n",
                "\n",
                "pred_rates = scramble_rates.merge(rusher_names, on='rusher_id', how='left')\n",
                "pred_rates['season_weight'] = pred_rates['season'].apply(scramble_rate_season_weight)\n",
                "pred_rates['weighted_samples'] = pred_rates['count'] * pred_rates['season_weight']\n",
                "pred_rates['weighted_scrambles'] = pred_rates['regr_scramble_rate'] * pred_rates['weighted_samples']\n",
                "\n",
                "scramble_rate_preds = (\n",
                "    pred_rates\n",
                "    .groupby(['rusher_id','name','position'], as_index=False)\n",
                "    .aggregate({'weighted_samples': 'sum', 'weighted_scrambles': 'sum'})\n",
                ")\n",
                "scramble_rate_preds['scramble_rate'] = scramble_rate_preds['weighted_scrambles'] / scramble_rate_preds['weighted_samples']\n",
                "scramble_rate_preds.sort_values('scramble_rate', ascending=False, inplace=True)\n",
                "scramble_rate_preds[scramble_rate_preds['position'] == 'QB'].head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "run_result_features = [\n",
                "    *rushing_exp_features,\n",
                "    'log_mean_yards',\n",
                "    'log_std_yards',\n",
                "    'yoe_mean',\n",
                "    'yoe_std',\n",
                "    'togo_std',\n",
                "    'yardline_std',\n",
                "    # 'yoe_var',\n",
                "    # 'togo_var',\n",
                "    # 'yardline_var',\n",
                "]\n",
                "run_result_yards_features = [*run_result_features, 'clock_runs_after']\n",
                "\n",
                "def make_run_result_df(df_: pd.DataFrame, yoe_df: pd.DataFrame, scrambling: bool) -> pd.DataFrame:\n",
                "    res_df = (\n",
                "        df_[df_['season'] <= CURRENT_SEASON]\n",
                "        .merge(yoe_df[['season','rusher_id','yoe_mean','yoe_std']], how='left', on=['season','rusher_id'])\n",
                "    )\n",
                "    mean_yds = YARDS_PER_SCRAMBLE if scrambling else YARDS_PER_DESIGNED_RUN\n",
                "    res_df['log_mean_yards'] = np.log( (mean_yds + res_df['yoe_mean']).clip(RUSHING_EPSILON) )\n",
                "    res_df['log_std_yards'] = np.log(res_df['yoe_std'])\n",
                "\n",
                "    # add interactions\n",
                "    res_df['yardline_std'] = res_df['yardline_pct'] * res_df['yoe_std']\n",
                "    res_df['togo_std'] = res_df['z_ydstogo'] * res_df['yoe_std']\n",
                "    # res_df['yoe_var'] = res_df['yoe_std'] ** 2\n",
                "    # res_df['yardline_var'] = res_df['yardline_pct'] * res_df['yoe_var']\n",
                "    # res_df['togo_var'] = res_df['z_ydstogo'] * res_df['yoe_var']\n",
                "    return res_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_logr_model(model: LogisticRegression, name: str, scrambling: bool, include_clock: bool = True) -> str:\n",
                "    ret = []\n",
                "    prefix = 'scrambling' if scrambling else 'designed_run'\n",
                "    ret.append(f'\\n    pub fn {prefix}_{name}_coef() -> RushingModel {{')\n",
                "    ret.append('        RushingModel {')\n",
                "    ret.append(f'            intercept: {model.intercept_[0]:.4f},')\n",
                "    fts = run_result_features if include_clock else run_result_yards_features\n",
                "    for f, c in zip(fts, model.coef_[0]):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    if include_clock:\n",
                "        ret.append(f'            clock_runs_after: 0.0,')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n",
                "\n",
                "def format_linr_model(model: PoissonRegressor, name: str, scrambling: bool) -> str:\n",
                "    ret = []\n",
                "    prefix = 'scrambling' if scrambling else 'designed_run'\n",
                "    ret.append(f'\\n    pub fn {prefix}_{name}_coef() -> RushingModel {{')\n",
                "    ret.append('        RushingModel {')\n",
                "    ret.append(f'            intercept: {model.intercept_:.4f},')\n",
                "    for f, c in zip(run_result_yards_features, model.coef_):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_models(df_: pd.DataFrame, scrambling: bool) -> List[str]:\n",
                "    suf = 'SCRAMBLING' if scrambling else 'DESIGNED_RUN'\n",
                "    fl_df_ = df_[df_['fumble_lost'] == 1].copy()\n",
                "    prob_fl_td_model = LogisticRegression(**LOGR_KWARGS)\n",
                "    prob_fl_td_model.fit(fl_df_[run_result_features], fl_df_['return_touchdown'])\n",
                "    safety_df = df_[(df_['fumble_lost'] == 0) & (df_['rush_touchdown'] == 0)].copy()\n",
                "    ruyards_df = df_[(df_['fumble_lost'] == 0) & (df_['rush_touchdown'] == 0) & (df_['safety'] == 0)].copy()\n",
                "    ruyards_df['pos_yards'] = (ruyards_df['rushing_yards'] > 0).astype(int)\n",
                "\n",
                "    nonpos_yards_df = ruyards_df[ruyards_df['pos_yards'] == 0].copy()\n",
                "    pos_yards_df = ruyards_df[ruyards_df['pos_yards'] == 1].copy()\n",
                "\n",
                "    models: List[str] = []\n",
                "\n",
                "    proj_fumble_lost_model = LogisticRegression(**LOGR_KWARGS)\n",
                "    proj_fumble_lost_model.fit(df_[run_result_features], df_['fumble_lost'])\n",
                "    models.append(format_logr_model(proj_fumble_lost_model, 'fumble_lost', scrambling))\n",
                "    \n",
                "    # fl_ins_prob = proj_fumble_lost_model.predict_proba(df_[run_result_features])[:,1]\n",
                "\n",
                "    models.append(format_logr_model(prob_fl_td_model, 'prob_fl_td', scrambling))\n",
                "    # flrtd_ins_prob = prob_fl_td_model.predict_proba(fl_df_[run_result_features])[:,1]\n",
                "\n",
                "    proj_run_td_model = LogisticRegression(**LOGR_KWARGS)\n",
                "    rtd_df = df_[df_['fumble_lost'] == 0].copy()\n",
                "    proj_run_td_model.fit(rtd_df[run_result_features], rtd_df['rush_touchdown'])\n",
                "    models.append(format_logr_model(proj_run_td_model, 'rush_td', scrambling))\n",
                "    # rtd_ins_prob = proj_run_td_model.predict_proba(rtd_df[run_result_features])[:,1]\n",
                "\n",
                "    # safeties can't happen on a scramble because it would be a sack\n",
                "    if len(set(safety_df['safety'])) > 1:\n",
                "        proj_safety_model = LogisticRegression(**LOGR_KWARGS)\n",
                "        proj_safety_model.fit(safety_df[run_result_features], safety_df['safety'])\n",
                "        models.append(format_logr_model(proj_safety_model, 'safety', scrambling))\n",
                "        # safety_ins_prob = proj_safety_model.predict_proba(safety_df[run_result_features])[:,1]\n",
                "        # safety_ins_prob.mean(), safety_ins_prob.std()\n",
                "\n",
                "    clock_runs_model = LogisticRegression(**LOGR_KWARGS)\n",
                "    clock_runs_model.fit(ruyards_df[run_result_features], ruyards_df['clock_runs_after'])\n",
                "    # clock_runs_ins_prob = clock_runs_model.predict_proba(ruyards_df[run_result_features])[:,1]\n",
                "    models.append(format_logr_model(clock_runs_model, 'clock_runs', scrambling))\n",
                "\n",
                "    if not scrambling:\n",
                "        ruyds_pos_model = LogisticRegression(**LOGR_KWARGS)\n",
                "        ruyds_pos_model.fit(ruyards_df[run_result_yards_features], ruyards_df['pos_yards'])\n",
                "        # ruyds_neg_ins_prob = ruyds_neg_model.predict_proba(ruyards_df[run_result_yards_features])[:,1]\n",
                "        models.append(format_logr_model(ruyds_pos_model, 'is_yards_pos_sign', scrambling, include_clock=False))\n",
                "\n",
                "    # nonneg_ruyds_bins = [i for i in range(int(nonneg_yards_df['rushing_yards'].min()), 1 + int(nonneg_yards_df['rushing_yards'].max()))]\n",
                "\n",
                "    # nonneg_yards_df['rushing_yards'].std(), ryoe_df['yoe_std'].mean()\n",
                "\n",
                "    posyards_model = PoissonRegressor(**POIS_KWARGS)\n",
                "    posyards_model.fit(pos_yards_df[run_result_yards_features], pos_yards_df['rushing_yards'] - 1)\n",
                "    # pos_yards_ins_proj = posyards_model.predict(pos_yards_df[run_result_yards_features])\n",
                "    # pos_yards_resid = (pos_yards_ins_proj - np.log(pos_yards_df['rushing_yards'])).var()\n",
                "    # print(f'const POS_{suf}_YARDS_RESID: f32 = {pos_yards_resid:.4f};')\n",
                "    # pos_yards_ins_proj.mean(), pos_yards_ins_proj.std()\n",
                "    models.append(format_linr_model(posyards_model, 'pos_yards', scrambling))\n",
                "\n",
                "    posyards_mean_preds = posyards_model.predict(pos_yards_df[run_result_yards_features])\n",
                "\n",
                "    posyards_var_model = PoissonRegressor(**POIS_KWARGS)\n",
                "    posyards_var_model.fit(pos_yards_df[run_result_yards_features], (pos_yards_df['rushing_yards'] - 1 - posyards_mean_preds) ** 2)\n",
                "    # pos_yards_var_ins_proj = posyards_var_model.predict(pos_yards_df[run_result_yards_features])\n",
                "    # pos_yards_var_resid = (pos_yards_var_ins_proj - np.log((pos_yards_df['rushing_yards'] - posyards_mean_preds) ** 2)).var()\n",
                "    # print(f'const POS_{suf}_YARDS_VAR_RESID: f32 = {pos_yards_var_resid:.4f};')\n",
                "    models.append(format_linr_model(posyards_var_model, 'pos_yards_var', scrambling))\n",
                "\n",
                "    if not scrambling:\n",
                "        negyards_model = PoissonRegressor(**POIS_KWARGS)\n",
                "        negyards_model.fit(nonpos_yards_df[run_result_yards_features], -1 * nonpos_yards_df['rushing_yards'])\n",
                "        # neg_yards_ins_proj = negyards_model.predict(nonpos_yards_df[run_result_yards_features])\n",
                "        # neg_yards_resid = (neg_yards_ins_proj + nonpos_yards_df['rushing_yards']).var()\n",
                "        # print(f'const NEG_{suf}_YARDS_RESID: f32 = {neg_yards_resid:.4f};')\n",
                "        models.append(format_linr_model(negyards_model, 'neg_yards', scrambling))\n",
                "    \n",
                "    return models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "proj_scramble_result = make_run_result_df(scramble_df, syoe_df, scrambling=True)\n",
                "proj_dr_result = make_run_result_df(designed_rush_df, ryoe_df, scrambling=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_str_parts = [\"use crate::models::rushing::RushingModel;\\n\", \"impl RushingModel {\"]\n",
                "model_str_parts.extend(build_models(proj_scramble_result, True))\n",
                "model_str_parts.extend(build_models(proj_dr_result, False))\n",
                "model_str_parts.append(\"}\")\n",
                "\n",
                "model_str = \"\\n\".join(model_str_parts)\n",
                "\n",
                "with open(f'{MODELS_PATH}/rushing/coef.rs', 'w') as f:\n",
                "    f.write(model_str)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# test whether negative binomial distribution is valid enough (it is)\n",
                "\n",
                "# mu = np.mean(nonneg_yards_df['rushing_yards'])\n",
                "# sigma_sqr = np.var(nonneg_yards_df['rushing_yards'])\n",
                "\n",
                "# n = mu**2 / (sigma_sqr - mu)\n",
                "# p = mu / sigma_sqr\n",
                "\n",
                "# distribution = nbinom(n=n, p=p)\n",
                "\n",
                "# values = pd.DataFrame([\n",
                "#     {'x': x, 'y': distribution.pmf(x)}\n",
                "#     for x in nonneg_ruyds_bins\n",
                "# ])\n",
                "# values['cdf'] = values['y'].cumsum()\n",
                "# values['ev'] = values['x'] * values['y']\n",
                "# print(values['ev'].sum())\n",
                "# values.plot(x='x', y='y')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def mscar_season_weight(season: int) -> float:\n",
                "    if season == CURRENT_SEASON:\n",
                "        return 1.0\n",
                "    if season == CURRENT_SEASON - 1:\n",
                "        return 0.1\n",
                "    return 0.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SNEAK_YARDS = 1\n",
                "proj_dr_result['ytg_1'] = ((proj_dr_result['yardline_100'] <= SNEAK_YARDS) | (proj_dr_result['ydstogo'] <= SNEAK_YARDS)).astype(int)\n",
                "proj_dr_result['green_zone'] = ((proj_dr_result['yardline_100'] <= 10) & (proj_dr_result['ytg_1'] == 0)).astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "team_carries = (\n",
                "    proj_dr_result\n",
                "    .groupby(['season','posteam'], as_index=False)\n",
                "    .aggregate({'playcall': 'count'})\n",
                "    .rename(columns={'playcall': 'team_carries'})\n",
                ")\n",
                "\n",
                "ms_carries = (\n",
                "    proj_dr_result\n",
                "    .groupby(['season','posteam','rusher_id'], as_index=False)\n",
                "    .aggregate({'playcall': 'count', 'green_zone': 'sum', 'ytg_1': 'sum'})\n",
                "    .rename(columns={'playcall': 'carries'})\n",
                "    .merge(team_carries, how='left', on=['season', 'posteam'])\n",
                ")\n",
                "\n",
                "prior_ytg_1 = ms_carries['ytg_1'].sum() / ms_carries['carries'].sum()\n",
                "prior_gz = ms_carries['green_zone'].sum() / ms_carries['carries'].sum()\n",
                "\n",
                "ms_carries['P(ytg1|car)'] = ms_carries['ytg_1'] / ms_carries['carries']\n",
                "ms_carries['P(gz|car)'] = ms_carries['green_zone'] / ms_carries['carries']\n",
                "ms_carries['P(normal}car)'] = 1 - ms_carries['P(gz|car)'] - ms_carries['P(ytg1|car)']\n",
                "ms_carries['ms'] = ms_carries['carries'] / ms_carries['team_carries']\n",
                "\n",
                "ms_carries['season_weight'] = ms_carries['season'].apply(mscar_season_weight)\n",
                "ms_carries['carries_weight'] = ms_carries['season_weight'] * ms_carries['carries']\n",
                "ms_carries['ytg1_weight'] = ms_carries['season_weight'] * ms_carries['ytg_1']\n",
                "ms_carries['gz_weight'] = ms_carries['season_weight'] * ms_carries['green_zone']\n",
                "\n",
                "ms_carries.sort_values(['ms', 'P(ytg1|car)','P(gz|car)'], ascending=False, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(f'{prior_ytg_1:.1%}', f'{prior_gz:.1%}', f'{1 - (prior_ytg_1 + prior_gz):.1%}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ms_carries.merge(rusher_names, how='left', on='rusher_id').head(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_ = \"\"\"\n",
                "P(_|carry) = 1 - P(ytg1|carry) - P(gz|carry)\n",
                "\n",
                "P(carry|1ytg) = P(1ytg|rush) * P(rush) / P(1ytg)\n",
                "P(carry|gz) = P(gz|rush) * P(rush) / P(gz)\n",
                "P(carry|_) = P(_|rush) * P(rush) / P(_)\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "weighted_carries = (\n",
                "    ms_carries[ms_carries['carries_weight'] > 0]\n",
                "    .groupby(['rusher_id'], as_index=False)\n",
                "    .aggregate({\n",
                "        'carries_weight': 'sum',\n",
                "        'ytg1_weight': 'sum',\n",
                "        'gz_weight': 'sum',\n",
                "    })\n",
                "    .merge(rosters[['rusher_id','team']], how='inner', on='rusher_id')\n",
                "    .dropna()\n",
                ")\n",
                "\n",
                "team_weighted_carries = (\n",
                "    weighted_carries\n",
                "    .groupby(['team'], as_index=False)\n",
                "    .aggregate({'carries_weight': 'sum'})\n",
                "    .rename(columns={'carries_weight': 'team_carries_weight'})\n",
                ")\n",
                "\n",
                "proj_ms_carries = weighted_carries.merge(team_weighted_carries, how='left', on='team')\n",
                "\n",
                "proj_ms_carries['prob_1ytg_given_carry'] = proj_ms_carries['ytg1_weight'] / proj_ms_carries['carries_weight']\n",
                "proj_ms_carries['prob_gz_given_carry'] = proj_ms_carries['gz_weight'] / proj_ms_carries['carries_weight']\n",
                "proj_ms_carries['ms_carries'] = proj_ms_carries['carries_weight'] / proj_ms_carries['team_carries_weight']\n",
                "\n",
                "proj_ms_carries.sort_values(['ms_carries'], ascending=False, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "write_ms_carries = (\n",
                "    proj_ms_carries\n",
                "    .merge(rusher_names, how='left', on='rusher_id')\n",
                "    .drop(columns=['carries_weight','ytg1_weight','gz_weight','team_carries_weight'])\n",
                "    .rename(columns={'posteam': 'team'})\n",
                "    [['team','rusher_id','name','position','ms_carries', 'prob_1ytg_given_carry', 'prob_gz_given_carry']]\n",
                "    .sort_values('ms_carries', ascending=False)\n",
                "    .reset_index(drop=True)\n",
                ")\n",
                "\n",
                "write_ms_carries['ms_carries'] = write_ms_carries['ms_carries'].round(decimals=3)\n",
                "write_ms_carries['prob_1ytg_given_carry'] = write_ms_carries['prob_1ytg_given_carry'].round(decimals=3)\n",
                "write_ms_carries['prob_gz_given_carry'] = write_ms_carries['prob_gz_given_carry'].round(decimals=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def yoe_season_weight(season: int) -> float:\n",
                "    return math.exp(0.5 * (season - CURRENT_SEASON))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_yoe_proj(df_: pd.DataFrame):\n",
                "    yoe_proj = df_.copy()\n",
                "    yoe_proj['season_weight'] = yoe_proj['season'].apply(yoe_season_weight)\n",
                "    yoe_proj['weighted_samples'] = yoe_proj['count'] * yoe_proj['season_weight']\n",
                "    yoe_proj['weighted_mean'] = yoe_proj['yoe_mean'] * yoe_proj['weighted_samples']\n",
                "    yoe_proj['weighted_var'] = yoe_proj['weighted_samples'] * yoe_proj['yoe_std'] ** 2\n",
                "    projs = (\n",
                "        yoe_proj\n",
                "        .groupby(['rusher_id'], as_index=False)\n",
                "        .aggregate({\n",
                "            'weighted_mean': 'sum',\n",
                "            'weighted_var': 'sum',\n",
                "            'weighted_samples': 'sum',\n",
                "        })\n",
                "    )\n",
                "    projs['yoe_mean'] = (projs['weighted_mean'] / projs['weighted_samples']).round(decimals=2)\n",
                "    projs['yoe_std'] = np.sqrt((projs['weighted_var'] / projs['weighted_samples'])).round(decimals=1)\n",
                "    projs['yoe_samples'] = projs['weighted_samples'].round(decimals=1)\n",
                "    return projs[['rusher_id','yoe_mean','yoe_std', 'yoe_samples']].sort_values('yoe_mean', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ryoe_proj = make_yoe_proj(ryoe_df)\n",
                "write_carry_projections = (\n",
                "    write_ms_carries\n",
                "    .merge(ryoe_proj, how='left', on='rusher_id')\n",
                "    .rename(columns={'rusher_id': 'player_id', 'yoe_mean': 'ryoe', 'yoe_std': 'ryoe_std'})\n",
                "    .drop(columns=['yoe_samples'])\n",
                ")\n",
                "write_carry_projections.head(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "syoe_proj = make_yoe_proj(syoe_df)\n",
                "write_scramble_proj = (\n",
                "    scramble_rate_preds\n",
                "    .merge(syoe_proj, on='rusher_id', how='left')\n",
                "    .merge(rosters[rosters['position'] == 'QB'][['rusher_id','team']], how='inner')\n",
                "    .rename(columns={'rusher_id': 'player_id', 'yoe_mean': 'syoe', 'yoe_std': 'syoe_std'})\n",
                "    [['team','player_id','name','position','scramble_rate','syoe','syoe_std']]\n",
                ")\n",
                "write_scramble_proj['scramble_rate'] = write_scramble_proj['scramble_rate'].round(decimals=3)\n",
                "write_scramble_proj.head(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "write_carry_projections.to_csv(f'{BASELINES_PATH}/carries.csv', index=False)\n",
                "write_scramble_proj.to_csv(f'{BASELINES_PATH}/scrambling.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "game_counts = (\n",
                "    pbp[pbp['season'] >= CURRENT_SEASON - 1]\n",
                "    .groupby(['season','posteam'], as_index=False)\n",
                "    .aggregate({'game_id': 'nunique'})\n",
                "    .rename(columns={'posteam': 'team', 'game_id': 'n_games'}).reset_index(drop=True)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "team_projections = (\n",
                "    game_counts\n",
                "    .merge(\n",
                "        right=line_coefs_df[line_coefs_df['side'] == 'off'][line_cols].rename(columns={'line_z': 'oline_rushing_z'}),\n",
                "        how='left',\n",
                "        on=['season','team']\n",
                "    )\n",
                "    .merge(\n",
                "        line_coefs_df[line_coefs_df['side'] == 'def'][line_cols].rename(columns={'line_z': 'dline_rushing_z'}),\n",
                "        how='left',\n",
                "        on=['season','team'],\n",
                "    )\n",
                "    .merge(off_penalties.rename(columns={'posteam': 'team'}), on=['season','team'])\n",
                "    .merge(def_penalties.rename(columns={'defteam': 'team'}), on=['season','team'])\n",
                ")\n",
                "\n",
                "team_projections['weight'] = team_projections['n_games'] * team_projections['season'].apply(yoe_season_weight)\n",
                "tp_cols = ['oline_rushing_z', 'dline_rushing_z']\n",
                "for c in tp_cols:\n",
                "    team_projections[c] *= team_projections['weight']\n",
                "\n",
                "\n",
                "write_projections = (\n",
                "    team_projections\n",
                "    .groupby(['team'], as_index=False)\n",
                "    .aggregate({c: 'sum' for c in tp_cols + ['weight']})\n",
                ")\n",
                "for c in tp_cols:\n",
                "    write_projections[c] = (write_projections[c] / write_projections['weight']).round(decimals=2)\n",
                "write_projections.drop(columns=['weight'], inplace=True)\n",
                "\n",
                "write_projections.to_csv(f'{BASELINES_PATH}/team_rushing.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
