{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from scipy.stats import norm\n",
                "from sklearn.linear_model import LogisticRegression, PoissonRegressor, Ridge\n",
                "import nfl_data_py\n",
                "\n",
                "from pbp.data import (\n",
                "    CURRENT_SEASON,\n",
                "    BASELINES_PATH,\n",
                "    MODELS_PATH,\n",
                "    LOGR_KWARGS,\n",
                "    POIS_KWARGS,\n",
                "    PROB_COMPLETION,\n",
                "    PROB_INTERCEPTION,\n",
                "    common_timeout_features,\n",
                "    state_features,\n",
                "    add_playcall_features,\n",
                "    add_clock_stops,\n",
                "    load_pbp_data,\n",
                "    make_proe_data,\n",
                ")\n",
                "\n",
                "pd.set_option('display.max_rows', None)\n",
                "pd.set_option('display.max_columns', None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEASONS = list(range(2017, CURRENT_SEASON + 1))\n",
                "\n",
                "_EPSILON = 1e-6\n",
                "\n",
                "MEAN_AIR_YARDS = 8.0\n",
                "EPSILON_AIR_YARDS = 0.01"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "OFFENSIVE_POSITIONS = {'QB','RB','FB','WR','TE'}\n",
                "this_season_rosters = nfl_data_py.import_seasonal_rosters(years=[CURRENT_SEASON])\n",
                "rosters = (\n",
                "    this_season_rosters[this_season_rosters['position'].isin(OFFENSIVE_POSITIONS)]\n",
                ")\n",
                "\n",
                "players = nfl_data_py.import_players()\n",
                "player_names = players[['gsis_id','display_name','position']].rename(columns={'gsis_id': 'player_id', 'display_name': 'name'})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    pbp.head(1)\n",
                "except:\n",
                "    pbp_copy = load_pbp_data(SEASONS, force_reload=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pbp = pbp_copy.copy()\n",
                "\n",
                "drive_keys = ['game_id','drive','posteam','defteam', 'posteam_score', 'defteam_score']\n",
                "drive_teams = (\n",
                "    pbp[~pbp['posteam'].isna() & ~pbp['defteam'].isna() & ~pbp['posteam_score'].isna() & ~pbp['defteam_score'].isna()]\n",
                "    [drive_keys]\n",
                "    .groupby(drive_keys, as_index=False)\n",
                "    .nth(0)\n",
                "    .rename(columns={'posteam': 'drive_offense', 'defteam': 'drive_defense', 'posteam_score': 'off_score', 'defteam_score': 'def_score'})\n",
                ")\n",
                "pbp = pbp.merge(drive_teams, on=['game_id', 'drive'], how='left').drop_duplicates(subset=['play_id','game_id'])\n",
                "\n",
                "pbp.loc[pbp['off_score'].isna(), 'off_score'] = pbp['posteam_score']\n",
                "pbp.loc[pbp['def_score'].isna(), 'def_score'] = pbp['defteam_score']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(offense_proes, defense_proes, offense_rz_proes, defense_rz_proes) = make_proe_data(pbp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dropback = ((pbp['play_type'] == 'pass') | (pbp['qb_scramble'] == 1)) & (pbp['two_point_attempt'] != 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "add_clock_stops(pbp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pbp['home_timeout'] = 0\n",
                "pbp['away_timeout'] = 0\n",
                "\n",
                "pbp.loc[pbp['timeout'] == 'OFFENSIVE_TIMEOUT', 'home_timeout'] = (pbp['drive_offense'] == pbp['home_team']).astype(int)\n",
                "pbp.loc[pbp['timeout'] == 'DEFENSIVE_TIMEOUT', 'home_timeout'] = (pbp['drive_defense'] == pbp['home_team']).astype(int)\n",
                "\n",
                "pbp.loc[pbp['timeout'] == 'OFFENSIVE_TIMEOUT', 'away_timeout'] = (pbp['drive_offense'] == pbp['away_team']).astype(int)\n",
                "pbp.loc[pbp['timeout'] == 'DEFENSIVE_TIMEOUT', 'away_timeout'] = (pbp['drive_defense'] == pbp['away_team']).astype(int)\n",
                "\n",
                "pbp['home_timeout_prev'] = pbp['home_timeout'].shift(1)\n",
                "pbp['away_timeout_prev'] = pbp['away_timeout'].shift(1)\n",
                "pbp['duplicate_timeout'] = (\n",
                "    ((pbp['home_timeout_prev'] == 1) & (pbp['home_timeout'] == 1))\n",
                "    | ((pbp['away_timeout_prev'] == 1) & (pbp['away_timeout'] == 1))\n",
                ")\n",
                "pbp.loc[pbp['home_timeout_prev'] == 1, 'home_timeout'] = 0\n",
                "pbp.loc[pbp['away_timeout_prev'] == 1, 'away_timeout'] = 0\n",
                "\n",
                "pbp.loc[pbp['duplicate_timeout'], 'timeout'] = 'DUPLICATE'\n",
                "pbp.loc[pbp['duplicate_timeout'], 'playcall'] = 'DUPLICATE_TIMEOUT'\n",
                "\n",
                "pbp['total_home_timeouts'] = pbp.groupby(['game_id','home_team', 'game_half'])['home_timeout'].cumsum()\n",
                "pbp['total_away_timeouts'] = pbp.groupby(['game_id','away_team', 'game_half'])['away_timeout'].cumsum()\n",
                "\n",
                "# ugh, probably fine. if the teams are null, then it's probably first play\n",
                "pbp['off_timeouts_left'] = 3\n",
                "pbp['def_timeouts_left'] = 3\n",
                "\n",
                "pbp.loc[pbp['drive_offense'] == pbp['home_team'], 'off_timeouts_left'] = 3 - pbp['total_home_timeouts']\n",
                "pbp.loc[pbp['drive_offense'] == pbp['away_team'], 'off_timeouts_left'] = 3 - pbp['total_away_timeouts']\n",
                "\n",
                "pbp.loc[pbp['drive_defense'] == pbp['home_team'], 'def_timeouts_left'] = 3 - pbp['total_home_timeouts']\n",
                "pbp.loc[pbp['drive_defense'] == pbp['away_team'], 'def_timeouts_left'] = 3 - pbp['total_away_timeouts']\n",
                "\n",
                "pbp['off_timeouts_remaining'] = pbp['posteam_timeouts_remaining'].combine_first(pbp['off_timeouts_left']).astype(int).clip(0, 3)\n",
                "pbp['def_timeouts_remaining'] = pbp['defteam_timeouts_remaining'].combine_first(pbp['def_timeouts_left']).astype(int).clip(0, 3)\n",
                "\n",
                "pbp['down'] = pbp['down'].apply(lambda x: str(int(x)) if not math.isnan(x) else None)\n",
                "pbp['qtr'] = pbp['qtr'].apply(lambda x: str(int(x)) if not math.isnan(x) else None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "line_strength_df = pbp[dropback][['season','posteam','defteam','qb_hit','sack','number_of_pass_rushers']].copy()\n",
                "line_strength_df.loc[line_strength_df['number_of_pass_rushers'].isna(), 'number_of_pass_rushers'] = 4.3\n",
                "line_strength_df.dropna(inplace=True)\n",
                "line_strength_df.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_line_features(season: int, response: str):\n",
                "    season_ls = line_strength_df[line_strength_df['season'] == season].reset_index(drop=True)\n",
                "    # more likely to be sacked is bad for offense, good for defense\n",
                "    off_dummies = -1 * pd.get_dummies(season_ls['posteam'], prefix='off')\n",
                "    def_dummies = pd.get_dummies(season_ls['defteam'], prefix='def')\n",
                "    season_ls[off_dummies.columns] = off_dummies\n",
                "    season_ls[def_dummies.columns] = def_dummies\n",
                "\n",
                "    features = ['number_of_pass_rushers', *list(off_dummies.columns), *list(def_dummies.columns)]\n",
                "\n",
                "    qbh_model = LogisticRegression(**LOGR_KWARGS)\n",
                "    qbh_model.fit(season_ls[features], season_ls[response])\n",
                "\n",
                "    return [\n",
                "        {\n",
                "            'season': season,\n",
                "            'side': f.split('_')[0],\n",
                "            'team': f.split('_')[1],\n",
                "            f'{response}_coef': c,\n",
                "        }\n",
                "        for f, c in zip(features[1:], qbh_model.coef_[0][1:])\n",
                "    ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "qb_sack_df = pbp[dropback][['season','passer_id','qb_hit','sack']].copy()\n",
                "qb_sack_df.loc[qb_sack_df['sack'] == 1, 'qb_hit'] = 1\n",
                "\n",
                "qb_sack_avoidance = (\n",
                "    qb_sack_df\n",
                "    .dropna()\n",
                "    .groupby(['season','passer_id'], as_index=False)\n",
                "    .aggregate({'qb_hit': 'sum', 'sack': 'sum'})\n",
                "    .rename(columns={'qb_hit': 'qb_hit_count', 'sack': 'sack_count'})\n",
                ")\n",
                "\n",
                "PRIOR_HITS = 10\n",
                "prior_prob = qb_sack_df['sack'].sum() / qb_sack_df['qb_hit'].sum()\n",
                "\n",
                "qb_sack_avoidance['qb_prob_sack_given_hit'] = (\n",
                "    (qb_sack_avoidance['sack_count'] + PRIOR_HITS * prior_prob)\n",
                "    / (qb_sack_avoidance['qb_hit_count'] + PRIOR_HITS)\n",
                ")\n",
                "qb_sack_avoidance.drop(columns=['qb_hit_count', 'sack_count'], inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sack_features = []\n",
                "for season in SEASONS:\n",
                "    sack_features.extend(get_line_features(season, 'sack'))\n",
                "\n",
                "qbhit_features = []\n",
                "for season in SEASONS:\n",
                "    qbhit_features.extend(get_line_features(season, 'qb_hit'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "line_features = pd.DataFrame(qbhit_features).merge(pd.DataFrame(sack_features), on=['season','side','team'])\n",
                "line_features['line_strength'] = 0.5 * line_features['qb_hit_coef'] + 0.5 * line_features['sack_coef']\n",
                "line_features['z'] = (line_features['line_strength'] - line_features['line_strength'].mean()) / line_features['line_strength'].std()\n",
                "\n",
                "joined_line_features = (\n",
                "    line_features[line_features['side'] == 'off'][['season','team','z']].rename(columns={'z': 'offense_pass_rush_z'})\n",
                "    .merge(\n",
                "        right=line_features[line_features['side'] == 'def'][['season','team','z']].rename(columns={'z': 'defense_pass_rush_z'}),\n",
                "        on=['season','team'],\n",
                "        how='inner',\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "pbp['dropback'] = ''\n",
                "pbp.loc[dropback, 'dropback'] = 'UNLABELED'\n",
                "pbp.loc[dropback & (pbp['pass_attempt'] == 1) & ~pbp['receiver_player_id'].isna(), 'dropback'] = 'TARGETED_RECEIVER'\n",
                "\n",
                "pbp.loc[pbp['qb_scramble'] == 1, 'dropback'] = 'QB_SCRAMBLE'\n",
                "pbp.loc[dropback & (pbp['pass_attempt'] == 1) & pbp['receiver_player_id'].isna(), 'dropback'] = 'THROWAWAY'\n",
                "\n",
                "\n",
                "pbp.loc[dropback & (pbp['sack'] == 1), 'dropback'] = 'SACK'\n",
                "\n",
                "pbp['sack_result'] = ''\n",
                "pbp.loc[pbp['sack'] == 1, 'sack_result'] = 'LOSS_OF_YARDS'\n",
                "pbp.loc[(pbp['sack'] == 1) & (pbp['safety'] == 1), 'sack_result'] = 'SAFETY'\n",
                "pbp.loc[(pbp['sack'] == 1) & (pbp['fumble_lost'] == 1) & (pbp['return_touchdown'] == 0), 'sack_result'] = 'FUMBLE_LOST'\n",
                "pbp.loc[(pbp['sack'] == 1) & (pbp['fumble_lost'] == 1) & (pbp['return_touchdown'] == 1), 'sack_result'] = 'FUMBLE_LOST_TD'\n",
                "\n",
                "offensive_penalty = pbp['penalty_team'] == pbp['posteam']\n",
                "defensive_penalty = pbp['penalty_team'] == pbp['defteam']\n",
                "\n",
                "# might mess with targeted if both occurred\n",
                "pbp.loc[dropback & offensive_penalty & (pbp['penalty'] == 1) & (pbp['complete_pass'] == 0), 'dropback'] = 'OFFENSIVE_PENALTY'\n",
                "pbp.loc[dropback & defensive_penalty & (pbp['penalty'] == 1) & (pbp['complete_pass'] == 0), 'dropback'] = 'DEFENSIVE_PENALTY'\n",
                "\n",
                "pbp['target_result'] = ''\n",
                "target = pbp['dropback'] == 'TARGETED_RECEIVER'\n",
                "pbp.loc[target, 'target_result'] = 'UNLABELED'\n",
                "pbp.loc[target & (pbp['pass_touchdown'] == 1), 'target_result'] = 'TD'\n",
                "pbp.loc[target & (pbp['interception'] == 1) & (pbp['return_touchdown'] == 0), 'target_result'] = 'INT'\n",
                "pbp.loc[target & (pbp['interception'] == 1) & (pbp['return_touchdown'] == 1), 'target_result'] = 'PICK_SIX'\n",
                "pbp.loc[target & (pbp['incomplete_pass'] == 1) & (pbp['fumble_lost'] == 0), 'target_result'] = 'INCOMPLETE'\n",
                "pbp.loc[target & (pbp['complete_pass'] == 1) & (pbp['fumble_lost'] == 0), 'target_result'] = 'CATCH'\n",
                "pbp.loc[target & (pbp['complete_pass'] == 1) & (pbp['fumble_lost'] == 0) & (pbp['penalty'] == 1) & defensive_penalty, 'target_result'] = 'CATCH_AND_PENALTY'\n",
                "pbp.loc[target & (pbp['complete_pass'] == 1) & (pbp['fumble_lost'] == 1), 'target_result'] = 'CATCH_AND_FUMBLE'\n",
                "\n",
                "pbp.loc[(pbp['qb_scramble'] == 1) & pbp['passer_id'].isna(), 'passer_id'] = pbp['rusher_id']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scramble_rate_df = pbp[dropback][['season','passer_id','qb_scramble']].dropna().reset_index(drop=True)\n",
                "scramble_rate_df['count'] = 1\n",
                "\n",
                "PRIOR_DROPBACKS = 10\n",
                "mean_scramble_rate = scramble_rate_df['qb_scramble'].mean()\n",
                "\n",
                "scramble_rates = (\n",
                "    scramble_rate_df[['season','passer_id','qb_scramble','count']]\n",
                "    .groupby(['season','passer_id'], as_index=False)\n",
                "    .aggregate({'qb_scramble': 'sum', 'count': 'count'})\n",
                ")\n",
                "scramble_rates['scramble_rate'] = (\n",
                "    (scramble_rates['qb_scramble'] + mean_scramble_rate * PRIOR_DROPBACKS)\n",
                "    / (scramble_rates['count'] + PRIOR_DROPBACKS)\n",
                ")\n",
                "scramble_rates.drop(columns=['qb_scramble','count'], inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "responses = [\n",
                "    'play_id',\n",
                "    'game_id',\n",
                "    'posteam',\n",
                "    'defteam',\n",
                "    'season',\n",
                "    'home_team',\n",
                "    'passer_id',\n",
                "    'dropback',\n",
                "    'sack',\n",
                "    'target_result',\n",
                "    'sack_result',\n",
                "    'qb_scramble',\n",
                "    'yards_gained',\n",
                "    'clock_runs_after',\n",
                "    'location',\n",
                "]\n",
                "\n",
                "raw_features = [\n",
                "    'down',\n",
                "    'ydstogo',\n",
                "    'goal_to_go',\n",
                "    'qtr', \n",
                "    'clock_running',\n",
                "    # 'quarter_seconds_remaining',\n",
                "    'yardline_100',\n",
                "    'off_score',\n",
                "    'def_score',\n",
                "    # 'play_clock',\n",
                "    'game_seconds_remaining',\n",
                "    'half_seconds_remaining',\n",
                "    # 'wp', \n",
                "    'off_timeouts_remaining',\n",
                "    'def_timeouts_remaining',\n",
                "    # 'total', 'spread_line',\n",
                "]\n",
                "\n",
                "cols = responses + raw_features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nondummy_completion_features = [\n",
                "    # including P(completion) is probably wrong bc correlates with what we want to extract\n",
                "    # 'log_prob_completion',\n",
                "    # is air yards factored into 'cp'? probably, but it's unclear and can't hurt\n",
                "    'air_yards_clipped',\n",
                "    'neg_log_air_yards',\n",
                "    'pos_log_air_yards',\n",
                "    'pos_log_air_yards_sq',\n",
                "    # 'log_air_yards',\n",
                "    # 'air_yards',\n",
                "    'offense_pass_rush_z',\n",
                "    'defense_pass_rush_z',\n",
                "    'off_def_pass_rush_z',\n",
                "]\n",
                "\n",
                "def get_completion_features(df_: pd.DataFrame, season: int):\n",
                "    season_target_df = df_[df_['season'] == season].reset_index(drop=True)\n",
                "\n",
                "    off_dummies = pd.get_dummies(season_target_df['posteam'], prefix='off')\n",
                "    def_dummies = pd.get_dummies(season_target_df['defteam'], prefix='def')\n",
                "\n",
                "    season_target_df[off_dummies.columns] = off_dummies\n",
                "    season_target_df[def_dummies.columns] = def_dummies\n",
                "\n",
                "    features = [\n",
                "        *nondummy_completion_features,\n",
                "        *sorted(off_dummies.columns),\n",
                "        *sorted(def_dummies.columns),\n",
                "    ]\n",
                "\n",
                "    comp_model = LogisticRegression(**LOGR_KWARGS)\n",
                "    comp_model.fit(season_target_df[features], season_target_df['complete_pass'])\n",
                "\n",
                "    int_model = LogisticRegression(**LOGR_KWARGS)\n",
                "    int_model.fit(season_target_df[features], season_target_df['interception'])\n",
                "\n",
                "    tmloc = len(nondummy_completion_features)\n",
                "    season_records = []\n",
                "    for (c, comp_f, int_f) in zip(features[tmloc:], comp_model.coef_[0, tmloc:], int_model.coef_[0, tmloc:]):\n",
                "        side, team = c.split('_')\n",
                "        season_records.append({\n",
                "            'season': season,\n",
                "            'side': side,\n",
                "            'team': team,\n",
                "            # completions are good for offense and bad for defense. vice versa for INTs\n",
                "            'comp_coef': (-1 if side == 'def' else 1) * comp_f,\n",
                "            'int_coef': (-1 if side == 'off' else 1) * int_f,\n",
                "        })\n",
                "\n",
                "    return season_records"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: remove this and project them too\n",
                "has_penalty = pbp['dropback'].isin({'OFFENSIVE_PENALTY','DEFENSIVE_PENALTY'})\n",
                "\n",
                "dropback_dataset = (\n",
                "    pd.get_dummies(pbp[(~has_penalty) & (~pbp['passer_id'].isna()) & dropback][cols], columns=['down', 'qtr', 'off_timeouts_remaining', 'def_timeouts_remaining'])\n",
                "    .merge(scramble_rates, on=['season','passer_id'], how='left').rename(columns={'scramble_rate': 'qb_scramble_rate'})\n",
                "    .merge(qb_sack_avoidance, on=['season','passer_id'], how='left')\n",
                "    .merge(offense_proes, on=['season','posteam'], how='left')\n",
                "    .merge(defense_proes, on=['season','defteam'], how='left')\n",
                "    .merge(offense_rz_proes, how='left', on=['posteam','season'])\n",
                "    .merge(defense_rz_proes, how='left', on=['defteam','season'])\n",
                "    .merge(joined_line_features[['season','team','offense_pass_rush_z']].rename(columns={'team': 'posteam'}), on=['season','posteam'], how='left')\n",
                "    .merge(joined_line_features[['season','team','defense_pass_rush_z']].rename(columns={'team': 'defteam'}), on=['season','defteam'], how='left')\n",
                "    .dropna()\n",
                ")\n",
                "\n",
                "add_playcall_features(dropback_dataset)\n",
                "\n",
                "dropback_dataset['log_qb_scramble'] = np.log(dropback_dataset['qb_scramble_rate'] + _EPSILON)\n",
                "dropback_dataset['log_qbps'] = np.log(dropback_dataset['qb_prob_sack_given_hit'] + _EPSILON)\n",
                "dropback_dataset[\"off_def_pass_rush_z\"] = dropback_dataset[\"offense_pass_rush_z\"] * dropback_dataset[\"defense_pass_rush_z\"]\n",
                "dropback_dataset[\"olpz_qbps\"] = (\n",
                "    dropback_dataset[\"offense_pass_rush_z\"] * dropback_dataset[\"log_qbps\"]\n",
                ")\n",
                "dropback_dataset[\"dlpz_qbps\"] = (\n",
                "    dropback_dataset[\"defense_pass_rush_z\"] * dropback_dataset[\"log_qbps\"]\n",
                ")\n",
                "dropback_dataset[\"olpz_scramble\"] = (\n",
                "    dropback_dataset[\"offense_pass_rush_z\"] * dropback_dataset[\"log_qb_scramble\"]\n",
                ")\n",
                "dropback_dataset[\"dlpz_scramble\"] = (\n",
                "    dropback_dataset[\"defense_pass_rush_z\"] * dropback_dataset[\"log_qb_scramble\"]\n",
                ")\n",
                "\n",
                "dropback_dataset['off_def_pass_rush_z'] = dropback_dataset['offense_pass_rush_z'] * dropback_dataset['defense_pass_rush_z']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def apply_ay_transforms(df_: pd.DataFrame):\n",
                "    df_['air_yards_clipped'] = df_['air_yards'].clip(-5, 50)\n",
                "    df_['neg_log_air_yards'] = np.log((-1 * df_['air_yards_clipped']).clip(1))\n",
                "    df_['pos_log_air_yards'] = np.log(df_['air_yards_clipped'].clip(1))\n",
                "    df_['pos_log_air_yards_sq'] = df_['pos_log_air_yards'] ** 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_df = (\n",
                "    dropback_dataset[dropback_dataset['dropback'] == 'TARGETED_RECEIVER']\n",
                "    .merge(pbp[['play_id','game_id','air_yards','cp','complete_pass','interception','receiver_id','return_yards','touchdown']], how='left', on=['play_id','game_id'])\n",
                "    .fillna({'return_yards': 0, 'touchdown': 0})\n",
                "    .dropna()\n",
                ")\n",
                "apply_ay_transforms(target_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ay_cp_df = target_df.groupby(['air_yards_clipped'], as_index=False).aggregate({'cp': 'mean'}).rename(columns={'cp': 'ay_cp'})\n",
                "\n",
                "# prob_cp_features = ['air_yards_clipped', 'neg_log_air_yards', 'pos_log_air_yards', 'pos_log_air_yards_sq']\n",
                "# prob_cp_model = LogisticRegression(**LOGR_KWARGS)\n",
                "# prob_cp_model.fit(target_df[prob_cp_features], target_df['complete_pass'])\n",
                "\n",
                "# to_pred = pd.DataFrame([{'air_yards': ay} for ay in range(-5, 51)])\n",
                "# apply_ay_transforms(to_pred)\n",
                "# to_pred['prob'] = prob_cp_model.predict_proba(to_pred[prob_cp_features])[:,1]\n",
                "\n",
                "# ay_cp_df.plot(x='air_yards_clipped', y='ay_cp', kind='scatter')\n",
                "# to_pred.plot(x='air_yards_clipped', y='prob', kind='scatter')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_season_features = []\n",
                "for season in SEASONS:\n",
                "    all_season_features.extend(get_completion_features(target_df, season))\n",
                "\n",
                "completion_features = pd.DataFrame(all_season_features)\n",
                "completion_features['comp_z'] = (completion_features['comp_coef'] - completion_features['comp_coef'].mean()) / completion_features['comp_coef'].std()\n",
                "completion_features['int_z'] = (completion_features['int_coef'] - completion_features['int_coef'].mean()) / completion_features['int_coef'].std()\n",
                "completion_features.drop(columns=['comp_coef','int_coef'], inplace=True)\n",
                "\n",
                "team_completion_features = (\n",
                "    (\n",
                "        completion_features[completion_features['side'] == 'off']\n",
                "        .rename(columns={'comp_z': 'off_comp_z', 'int_z': 'off_int_z'})\n",
                "        .drop(columns=['side'])\n",
                "    )\n",
                "    .merge(\n",
                "        right=(\n",
                "            completion_features[completion_features['side'] == 'def']\n",
                "            .rename(columns={'comp_z': 'def_comp_z', 'int_z': 'def_int_z'})\n",
                "            .drop(columns=['side'])\n",
                "        ),\n",
                "        how='inner',\n",
                "        on=['season','team']\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# target_df.groupby(['air_yards'], as_index=False).aggregate({'cp': 'mean'}).plot(x='air_yards', y='cp', kind='scatter')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pass_skill_df = (\n",
                "    target_df\n",
                "    .merge(\n",
                "        right=team_completion_features[['season','team','off_comp_z','off_int_z']],\n",
                "        how='left',\n",
                "        left_on=['season','posteam'],\n",
                "        right_on=['season','team']\n",
                "    ).merge(\n",
                "        right=team_completion_features[['season','team','def_comp_z','def_int_z']],\n",
                "        how='left',\n",
                "        left_on=['season','defteam'],\n",
                "        right_on=['season','team'],\n",
                "    ).rename(columns={\n",
                "        'off_comp_z': 'offense_completion_z',\n",
                "        'off_int_z': 'offense_interception_z',\n",
                "        'def_comp_z': 'defense_completion_z',\n",
                "        'def_int_z': 'defense_interception_z',\n",
                "    })\n",
                ")\n",
                "\n",
                "pass_skill_df['def_comp_scramble'] = pass_skill_df['defense_pass_rush_z'] * pass_skill_df['log_qb_scramble']\n",
                "pass_skill_df['def_int_scramble'] = pass_skill_df['defense_pass_rush_z'] * pass_skill_df['log_qb_scramble']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# team_completion_features[team_completion_features['season'] == CURRENT_SEASON]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dropback_specific_features = [\n",
                "    \"qb_scramble_rate\",\n",
                "    \"log_qb_scramble\",\n",
                "    \"qb_prob_sack_given_hit\",\n",
                "    \"log_qbps\",\n",
                "    \"offense_pass_rush_z\",\n",
                "    \"defense_pass_rush_z\",\n",
                "    \"off_def_pass_rush_z\",\n",
                "    \"defense_completion_z\",\n",
                "    'defense_interception_z',\n",
                "    'def_comp_scramble',\n",
                "    'def_int_scramble',\n",
                "    \"olpz_qbps\",\n",
                "    \"dlpz_qbps\",\n",
                "    \"olpz_scramble\",\n",
                "    \"dlpz_scramble\",\n",
                "]\n",
                "dropback_features = [*common_timeout_features, *state_features, *dropback_specific_features]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def_z_features = ['defense_completion_z','defense_interception_z']\n",
                "ps_exp_features = [*nondummy_completion_features, *def_z_features]\n",
                "qb_compl_model = LogisticRegression(**LOGR_KWARGS)\n",
                "qb_compl_model.fit(pass_skill_df[ps_exp_features], pass_skill_df['complete_pass'])\n",
                "pass_skill_df['prob_completion'] = qb_compl_model.predict_proba(pass_skill_df[ps_exp_features])[:,1]\n",
                "\n",
                "qb_int_model = LogisticRegression(**LOGR_KWARGS)\n",
                "qb_int_model.fit(pass_skill_df[ps_exp_features], pass_skill_df['interception'])\n",
                "pass_skill_df['prob_interception'] = qb_int_model.predict_proba(pass_skill_df[ps_exp_features])[:,1]\n",
                "\n",
                "qb_airyards_model = Ridge(**POIS_KWARGS)\n",
                "qb_airyards_model.fit(pass_skill_df[dropback_features + def_z_features], pass_skill_df['air_yards'])\n",
                "pass_skill_df['exp_air_yards'] = qb_airyards_model.predict(pass_skill_df[dropback_features + def_z_features])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "qb_pass_skill_df = pass_skill_df.copy()\n",
                "qb_pass_skill_df['comp_oe'] = qb_pass_skill_df['complete_pass'] - qb_pass_skill_df['prob_completion']\n",
                "qb_pass_skill_df['int_ue'] = -1 * (qb_pass_skill_df['interception'] - qb_pass_skill_df['prob_interception'])\n",
                "qb_pass_skill_df['ay_oe'] = qb_pass_skill_df['air_yards'] - qb_pass_skill_df['exp_air_yards']\n",
                "qb_pass_skill_df['ay_std'] = qb_pass_skill_df['ay_oe']  # hack to aggregate cleaner\n",
                "\n",
                "avg_ayoe_std = qb_pass_skill_df['ay_oe'].std()\n",
                "avg_adot = qb_pass_skill_df['air_yards'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PRIOR_ATT_COUNT = 50\n",
                "\n",
                "qb_features_df = (\n",
                "    qb_pass_skill_df\n",
                "    .groupby(['season','passer_id'], as_index=False)\n",
                "    .aggregate({\n",
                "        'play_id': 'count',\n",
                "        'comp_oe': 'mean',\n",
                "        'int_ue': 'mean',\n",
                "        'ay_oe': 'mean',\n",
                "        'ay_std': 'std',\n",
                "    })\n",
                "    .rename(columns={'play_id': 'count'})\n",
                ")\n",
                "qb_features_df.loc[qb_features_df['ay_std'].isna(), 'ay_std'] = avg_ayoe_std\n",
                "qb_features_df['comp_oe'] = qb_features_df['comp_oe'] * qb_features_df['count'] / (qb_features_df['count'] + PRIOR_ATT_COUNT)\n",
                "qb_features_df['int_ue'] = qb_features_df['int_ue'] * qb_features_df['count'] / (qb_features_df['count'] + PRIOR_ATT_COUNT)\n",
                "qb_features_df['ay_oe'] = qb_features_df['ay_oe'] * qb_features_df['count'] / (qb_features_df['count'] + PRIOR_ATT_COUNT)\n",
                "# add variances properly\n",
                "qb_features_df['ay_std'] = np.sqrt((qb_features_df['count'] * qb_features_df['ay_std'] ** 2 + PRIOR_ATT_COUNT * avg_ayoe_std ** 2) / (qb_features_df['count'] + PRIOR_ATT_COUNT))\n",
                "\n",
                "qb_features_df['log_qb_mean_ay'] = np.log((MEAN_AIR_YARDS + qb_features_df['ay_oe']).clip(EPSILON_AIR_YARDS))\n",
                "qb_features_df['log_qb_std_ay'] = np.log(qb_features_df['ay_std'])\n",
                "qb_features_df['log_qb_comp_prob'] = np.log(PROB_COMPLETION + qb_features_df['comp_oe'])\n",
                "qb_features_df['log_qb_int_prob'] = np.log( (PROB_INTERCEPTION - qb_features_df['int_ue']).clip(_EPSILON) )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# qb_features_df[qb_features_df['season'] == CURRENT_SEASON].merge(player_names, left_on=['passer_id'], right_on=['player_id']).sort_values('count', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "qb_skill_features = [\n",
                "    'log_qb_comp_prob',\n",
                "    'log_qb_int_prob',\n",
                "    'qb_ay_oe',\n",
                "    'log_qb_mean_ay',\n",
                "    'qb_ay_std',\n",
                "    'log_qb_std_ay',\n",
                "    'qb_def_comp',\n",
                "    'qb_def_int',\n",
                "]\n",
                "dropback_qb_features = [*dropback_features, *qb_skill_features]\n",
                "\n",
                "dataset = (\n",
                "    dropback_dataset\n",
                "    .merge(\n",
                "        right=team_completion_features[['season','team','def_comp_z','def_int_z']],\n",
                "        how='left',\n",
                "        left_on=['season','defteam'],\n",
                "        right_on=['season','team'],\n",
                "    )\n",
                "    .merge(\n",
                "        right=qb_features_df,\n",
                "        how='left',\n",
                "        on=['season','passer_id'],\n",
                "    )\n",
                "    .rename(columns={\n",
                "        'def_comp_z': 'defense_completion_z',\n",
                "        'def_int_z': 'defense_interception_z',\n",
                "        'comp_oe': 'qb_comp_oe',\n",
                "        'int_ue': 'qb_int_ue',\n",
                "        'ay_oe': 'qb_ay_oe',\n",
                "        'ay_std': 'qb_ay_std',\n",
                "    })\n",
                "    .dropna()\n",
                ")\n",
                "\n",
                "dataset['qb_def_comp'] = dataset['log_qb_comp_prob'] + dataset['defense_completion_z']\n",
                "dataset['qb_def_int'] = dataset['log_qb_int_prob'] + dataset['defense_interception_z']\n",
                "dataset['def_comp_scramble'] = dataset['defense_pass_rush_z'] * dataset['log_qb_scramble']\n",
                "dataset['def_int_scramble'] = dataset['defense_pass_rush_z'] * dataset['log_qb_scramble']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_logr_model(model: LogisticRegression, name: str) -> str:\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> DropbackModel {{')\n",
                "    ret.append('        DropbackModel {')\n",
                "    ret.append(f'            intercept: {model.intercept_[0]:.4f},')\n",
                "    for f, c in zip(dropback_features, model.coef_[0]):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n",
                "\n",
                "def format_linr_model(model: PoissonRegressor, name: str):\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> DropbackModel {{')\n",
                "    ret.append('        DropbackModel {')\n",
                "    ret.append(f'            intercept: {model.intercept_:.4f},')\n",
                "    for f, c in zip(dropback_features, model.coef_):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print('pub struct DropbackModel {')\n",
                "# print('    pub intercept: f32,')\n",
                "# for f in dropback_features:\n",
                "#     print(f'    pub {f}: f32,')\n",
                "# print('}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# NOTE: clock always runs after a sack\n",
                "sack_outcome_df = dataset[dataset['sack'] == 1].reset_index(drop=True)\n",
                "sack_outcome_df['sack_safety'] = (sack_outcome_df['sack_result'] == 'SAFETY')\n",
                "sack_outcome_df['sack_fumble_lost_notd'] = (sack_outcome_df['sack_result'] == 'FUMBLE_LOST').astype(int)\n",
                "sack_outcome_df['sack_fumble_lost_td'] = (sack_outcome_df['sack_result'] == 'FUMBLE_LOST_TD').astype(int)\n",
                "sack_outcome_df['sack_fumble_lost'] = sack_outcome_df['sack_fumble_lost_notd'] + sack_outcome_df['sack_fumble_lost_td']\n",
                "sack_outcome_df['loss_of_yards'] = 1 - sack_outcome_df['sack_safety'] - sack_outcome_df['sack_fumble_lost']\n",
                "\n",
                "sack_yards_lost_df = sack_outcome_df[sack_outcome_df['loss_of_yards'] == 1].reset_index(drop=True)\n",
                "sack_yards_lost_df['yards_lost'] = -1 * sack_yards_lost_df['yards_gained']\n",
                "\n",
                "nonsack_df = dataset[dataset['sack'] == 0].reset_index(drop=True)\n",
                "throwaway_prob_df = dataset[(dataset['sack'] == 0) & (dataset['qb_scramble'] == 0)].reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sack_model = LogisticRegression(**LOGR_KWARGS)\n",
                "sack_model.fit(dataset[dropback_qb_features], dataset['sack'])\n",
                "\n",
                "sack_safety_model = LogisticRegression(**LOGR_KWARGS)\n",
                "sack_safety_model.fit(sack_outcome_df[dropback_qb_features], sack_outcome_df['sack_safety'])\n",
                "\n",
                "sack_fumblelost_model = LogisticRegression(**LOGR_KWARGS)\n",
                "sack_fumblelost_model.fit(sack_outcome_df[dropback_qb_features], sack_outcome_df['sack_fumble_lost'])\n",
                "\n",
                "sack_fl_td_model = LogisticRegression(**LOGR_KWARGS)\n",
                "sack_fl_td_model.fit(sack_outcome_df[sack_outcome_df['sack_fumble_lost'] == 1][dropback_qb_features], sack_outcome_df[sack_outcome_df['sack_fumble_lost'] == 1]['sack_fumble_lost_td'])\n",
                "\n",
                "sack_yards_lost_model = PoissonRegressor(**POIS_KWARGS)\n",
                "sack_yards_lost_model.fit(sack_yards_lost_df[dropback_qb_features], sack_yards_lost_df['yards_lost'])\n",
                "# sack_yards_lost_pred = sack_yards_lost_model.predict(sack_yards_lost_df[dropback_features])\n",
                "# sack_yards_lost_resid = (sack_yards_lost_pred - sack_yards_lost_df['yards_lost']).var()\n",
                "# print(f'const SACK_YARDS_LOST_RESID: f32 = {sack_yards_lost_resid:.4f};')\n",
                "\n",
                "scramble_model = LogisticRegression(**LOGR_KWARGS)\n",
                "scramble_model.fit(nonsack_df[dropback_qb_features], nonsack_df['qb_scramble'])\n",
                "\n",
                "throwaway_model = LogisticRegression(**LOGR_KWARGS)\n",
                "throwaway_model.fit(throwaway_prob_df[dropback_qb_features], throwaway_prob_df['dropback'] == 'THROWAWAY')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ins_scrambles = scramble_model.predict_proba(nonsack_df[dropback_qb_features])\n",
                "ins_scrambles.mean(axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models_str_parts = [\"use crate::models::dropback::DropbackModel;\\n\", \"impl DropbackModel {\"]\n",
                "\n",
                "models_str_parts.append(format_logr_model(sack_model, 'prob_sack'))\n",
                "models_str_parts.append(format_logr_model(sack_safety_model, 'prob_sack_safety'))\n",
                "models_str_parts.append(format_logr_model(sack_fumblelost_model, 'prob_sack_fumble_lost'))\n",
                "models_str_parts.append(format_logr_model(sack_fl_td_model, 'prob_sack_fumble_lost_td'))\n",
                "models_str_parts.append(format_linr_model(sack_yards_lost_model, 'sack_yards_lost'))\n",
                "\n",
                "models_str_parts.append(format_logr_model(scramble_model, 'prob_scramble'))\n",
                "models_str_parts.append(format_logr_model(throwaway_model, 'prob_throwaway'))\n",
                "models_str_parts.append(\"}\")\n",
                "\n",
                "models_str = '\\n'.join(models_str_parts)\n",
                "\n",
                "with open(f'{MODELS_PATH}/dropback/coef.rs', 'w') as f:\n",
                "    f.write(models_str)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wr_train_df = (\n",
                "    pass_skill_df\n",
                "    .merge(qb_features_df.drop(columns=['count']), how='left', on=['season','passer_id'])\n",
                "    .rename(columns={'ay_oe': 'qb_ay_oe', 'ay_std': 'qb_ay_std', 'comp_oe': 'qb_comp_oe', 'int_ue': 'qb_int_ue'})\n",
                ")\n",
                "# hack to aggregate cleaner\n",
                "wr_train_df['air_yards_std'] = wr_train_df['air_yards']\n",
                "wr_train_df['qb_def_comp'] = wr_train_df['log_qb_comp_prob'] * wr_train_df['defense_completion_z']\n",
                "wr_train_df['qb_def_int'] = wr_train_df['log_qb_int_prob'] * wr_train_df['defense_interception_z']\n",
                "\n",
                "qb_acc_features = ['log_qb_comp_prob', 'log_qb_int_prob']\n",
                "def_x_features = ['qb_def_comp', 'qb_def_int']\n",
                "qb_ay_features = ['qb_ay_oe','qb_ay_std', 'log_qb_mean_ay', 'log_qb_std_ay']\n",
                "qb_throw_features = ['prob_completion', *qb_acc_features, *def_z_features, *def_x_features]\n",
                "\n",
                "prod_airyards_features = [*dropback_features, *qb_ay_features]\n",
                "prod_target_features = [*dropback_features, *qb_acc_features, *def_x_features, 'air_yards', 'neg_log_air_yards', 'pos_log_air_yards', 'pos_log_air_yards_sq']\n",
                "\n",
                "wr_compl_model = LogisticRegression(**LOGR_KWARGS)\n",
                "wr_compl_model.fit(wr_train_df[qb_throw_features], wr_train_df['complete_pass'])\n",
                "wr_train_df['prob_catch'] = wr_compl_model.predict_proba(wr_train_df[qb_throw_features])[:,1]\n",
                "wr_train_df['catch_oe'] = wr_train_df['complete_pass'] - wr_train_df['prob_catch']\n",
                "\n",
                "wr_train_df['is_pos_air_yards'] = (wr_train_df['air_yards'] > 0).astype(int)\n",
                "pos_ay_df = wr_train_df[wr_train_df['is_pos_air_yards'] == 1].reset_index(drop=True)\n",
                "neg_ay_df = wr_train_df[wr_train_df['is_pos_air_yards'] == 0].reset_index(drop=True)\n",
                "\n",
                "is_pos_air_yards_model = LogisticRegression(**LOGR_KWARGS)\n",
                "is_pos_air_yards_model.fit(wr_train_df[prod_airyards_features], wr_train_df['is_pos_air_yards'])\n",
                "\n",
                "neg_air_yards_model = PoissonRegressor(**POIS_KWARGS)\n",
                "neg_air_yards_model.fit(neg_ay_df[prod_airyards_features], -1 * neg_ay_df['air_yards'])\n",
                "# neg_ay_pred = neg_air_yards_model.predict(neg_ay_df[prod_airyards_features])\n",
                "# neg_ay_resid = (-1 * neg_ay_df['air_yards'] - neg_ay_pred).var()\n",
                "# print(f'const NEG_AIR_YARDS_RESID: f32 = {neg_ay_resid:.4f};')\n",
                "\n",
                "pos_air_yards_model = PoissonRegressor(**POIS_KWARGS)\n",
                "pos_air_yards_model.fit(pos_ay_df[prod_airyards_features], pos_ay_df['air_yards'] - 1)\n",
                "pos_ay_pred = pos_air_yards_model.predict(pos_ay_df[prod_airyards_features])\n",
                "# pos_ay_resid = (pos_ay_df['air_yards'] - pos_ay_pred).var()\n",
                "# print(f'const POS_AIR_YARDS_RESID: f32 = {pos_ay_resid:.4f};')\n",
                "\n",
                "pos_air_yards_var_model = PoissonRegressor(**POIS_KWARGS)\n",
                "pos_air_yards_var_model.fit(pos_ay_df[prod_airyards_features], (pos_ay_df['air_yards'] - 1 - pos_ay_pred) ** 2)\n",
                "pos_ay_var_pred = pos_air_yards_var_model.predict(pos_ay_df[prod_airyards_features])\n",
                "pos_ay_resid = (np.log((pos_ay_df['air_yards'] - pos_ay_pred) ** 2) - pos_ay_var_pred).var()\n",
                "# print(f'const POS_AIR_YARDS_VAR_RESID: f32 = {pos_ay_resid:.4f};')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from scipy.stats import nbinom\n",
                "\n",
                "# # test whether negative binomial distribution is valid enough (it is)\n",
                "\n",
                "# mu = np.mean(pos_ay_df['air_yards'])\n",
                "# sigma_sqr = np.var(pos_ay_df['air_yards'])\n",
                "\n",
                "# n = mu**2 / (sigma_sqr - mu)\n",
                "# p = mu / sigma_sqr\n",
                "\n",
                "# distribution = nbinom(n=n, p=p)\n",
                "\n",
                "# nonneg_airyds_bins = [i for i in range(int(pos_ay_df['air_yards'].min()), 1 + int(pos_ay_df['air_yards'].max()))]\n",
                "# values = pd.DataFrame([\n",
                "#     {'x': x, 'y': distribution.pmf(x)}\n",
                "#     for x in nonneg_airyds_bins\n",
                "# ])\n",
                "# values['cdf'] = values['y'].cumsum()\n",
                "# values['ev'] = values['x'] * values['y']\n",
                "# print(values['ev'].sum())\n",
                "# values.plot(x='x', y='y')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# mean_features = wr_train_df[prod_target_features].mean(axis=0).to_dict()\n",
                "# coefs = dict(zip(prod_target_features, is_pos_air_yards_model.coef_[0]))\n",
                "\n",
                "# contribs = {\n",
                "#     f: mean_features[f] * coefs[f]\n",
                "#     for f in prod_target_features\n",
                "# }\n",
                "# # sorted(contribs.items(), key=lambda x: x[1], reverse=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PRIOR_TARGET_COUNT = 30\n",
                "\n",
                "xyac_pbp_df = (\n",
                "    target_df\n",
                "    .merge(pbp[['play_id','game_id','yards_after_catch','xyac_mean_yardage']], how='left', on=['play_id','game_id'])\n",
                "    .dropna()\n",
                ")\n",
                "\n",
                "mean_xyac = xyac_pbp_df['xyac_mean_yardage'].mean()\n",
                "\n",
                "xyac_season_df = (\n",
                "    xyac_pbp_df\n",
                "    .groupby(['season', 'receiver_id'], as_index=False)\n",
                "    .aggregate({'xyac_mean_yardage': 'mean', 'play_id': 'count'})\n",
                "    .rename(columns={'play_id': 'targets', 'receiver_id': 'player_id'})\n",
                ")\n",
                "xyac_season_df['xyac'] = (\n",
                "    (xyac_season_df['xyac_mean_yardage'] * xyac_season_df['targets'] + PRIOR_TARGET_COUNT * mean_xyac)\n",
                "    / (xyac_season_df['targets'] + PRIOR_TARGET_COUNT)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PRIOR_REC_COUNT = 20\n",
                "\n",
                "yac_oe_pbp_df = (\n",
                "    target_df[(target_df['complete_pass'] == 1)]\n",
                "    .merge(pbp[['play_id','game_id','yards_after_catch','xyac_mean_yardage','pass_touchdown']], how='left', on=['play_id','game_id'])\n",
                "    .dropna()\n",
                ")\n",
                "yac_oe_pbp_df['yac_oe'] = yac_oe_pbp_df['yards_after_catch'] - yac_oe_pbp_df['xyac_mean_yardage']\n",
                "\n",
                "def_yac_oe_df = (\n",
                "    yac_oe_pbp_df\n",
                "    .groupby(['season', 'defteam'], as_index=False)\n",
                "    .aggregate({'yac_oe': 'mean', 'play_id': 'count'})\n",
                "    .rename(columns={'play_id': 'catches', 'defteam': 'team', 'yac_oe': 'def_yac_oe'})\n",
                ")\n",
                "\n",
                "yac_oe_season_df = (\n",
                "    yac_oe_pbp_df\n",
                "    .groupby(['season', 'receiver_id'], as_index=False)\n",
                "    .aggregate({'yac_oe': 'mean', 'play_id': 'count'})\n",
                "    .rename(columns={'play_id': 'catches', 'receiver_id': 'player_id'})\n",
                ")\n",
                "yac_oe_season_df['yac_oe'] = yac_oe_season_df['yac_oe'] * yac_oe_season_df['catches'] / (yac_oe_season_df['catches'] + PRIOR_REC_COUNT)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wr_rec_skills_df = (\n",
                "    wr_train_df\n",
                "    .groupby(['season','receiver_id'], as_index=False)\n",
                "    .aggregate({'catch_oe': 'mean', 'air_yards': 'mean', 'air_yards_std': 'std', 'play_id': 'count'})\n",
                "    .rename(columns={'play_id': 'targets', 'air_yards': 'adot', 'air_yards_std': 'adot_std', 'receiver_id': 'player_id'})\n",
                ")\n",
                "\n",
                "wr_rec_skills_df.loc[wr_rec_skills_df['adot_std'].isna(), 'adot_std'] = avg_ayoe_std\n",
                "\n",
                "prior_tgt_count = PRIOR_TARGET_COUNT + wr_rec_skills_df['targets']\n",
                "wr_rec_skills_df['catch_oe'] = (wr_rec_skills_df['catch_oe'] * wr_rec_skills_df['targets']) / prior_tgt_count\n",
                "wr_rec_skills_df['adot'] = (PRIOR_TARGET_COUNT * avg_adot + wr_rec_skills_df['adot'] * wr_rec_skills_df['targets']) / prior_tgt_count\n",
                "wr_rec_skills_df['adot_std'] = np.sqrt((PRIOR_TARGET_COUNT * avg_ayoe_std ** 2 + wr_rec_skills_df['targets'] * wr_rec_skills_df['adot_std'] ** 2) / prior_tgt_count)\n",
                "\n",
                "wr_features = (\n",
                "    wr_rec_skills_df\n",
                "    .merge(xyac_season_df.drop(columns=['targets']), on=['season','player_id'], how='left')\n",
                "    .merge(yac_oe_season_df, on=['season', 'player_id'], how='left')\n",
                ")\n",
                "\n",
                "wr_features.loc[wr_features['catches'].isna(), 'catches'] = 0\n",
                "wr_features.loc[wr_features['xyac'].isna(), 'xyac'] = mean_xyac\n",
                "wr_features.loc[wr_features['yac_oe'].isna(), 'yac_oe'] = 0.0\n",
                "\n",
                "wr_features['log_wr_adot'] = np.log(wr_features['adot'].clip(EPSILON_AIR_YARDS))\n",
                "wr_features['log_wr_xyac'] = np.log(wr_features['xyac'].clip(EPSILON_AIR_YARDS))\n",
                "wr_features['wr_yac_oe_sq'] = wr_features['yac_oe'] ** 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tgt_outcome_features = [\n",
                "    *prod_target_features,\n",
                "    'qb_ay_oe', 'log_qb_mean_ay',\n",
                "    'wr_adot', 'log_wr_adot',\n",
                "    'wr_xyac', 'log_wr_xyac',\n",
                "    'wr_yac_oe', 'wr_yac_oe_sq', 'def_yac_oe',\n",
                "    'log_wr_catch_prob', 'qb_wr_lcp',\n",
                "]\n",
                "yac_outcome_features = [*tgt_outcome_features, 'clock_runs_after']\n",
                "CATCH_OUTCOMES = {'CATCH', 'CATCH_AND_FUMBLE', 'CATCH_AND_PENALTY'}\n",
                "INT_OUTCOMES = {'INT', 'PICK_SIX'}\n",
                "\n",
                "target_outcomes_df = (\n",
                "    wr_train_df\n",
                "    .drop(columns=['catch_oe'])\n",
                "    .merge(\n",
                "        wr_features.rename(columns={\n",
                "            'adot': 'wr_adot',\n",
                "            'catch_oe': 'wr_catch_oe',\n",
                "            'yac_oe': 'wr_yac_oe',\n",
                "            'xyac': 'wr_xyac',\n",
                "        }),\n",
                "        how='left',\n",
                "        left_on=['season','receiver_id'],\n",
                "        right_on=['season', 'player_id']\n",
                "    )\n",
                "    .merge(\n",
                "        right=def_yac_oe_df.rename(columns={'team': 'defteam'}),\n",
                "        how='left',\n",
                "        on=['season','defteam']\n",
                "    )\n",
                ")\n",
                "\n",
                "target_outcomes_df['pos_log_air_yards'] = np.log(target_outcomes_df['air_yards'].clip(1))\n",
                "target_outcomes_df['pos_log_air_yards_sq'] = target_outcomes_df['pos_log_air_yards'] ** 2\n",
                "target_outcomes_df['neg_log_air_yards'] = np.log((-1 * target_outcomes_df['air_yards']).clip(1))\n",
                "target_outcomes_df['log_wr_catch_prob'] = np.log(PROB_COMPLETION + target_outcomes_df['wr_catch_oe'])\n",
                "target_outcomes_df['qb_wr_lcp'] = target_outcomes_df['log_qb_comp_prob'] * target_outcomes_df['log_wr_catch_prob']\n",
                "target_outcomes_df['interception'] = (target_outcomes_df['target_result'].isin({'INT', 'PICK_SIX'})).astype(int)\n",
                "\n",
                "int_outcome_df = target_outcomes_df[target_outcomes_df['interception'] == 1].reset_index(drop=True)\n",
                "int_outcome_df['pick_six'] = (int_outcome_df['target_result'] == 'PICK_SIX').astype(int)\n",
                "\n",
                "target_outcomes_df['completion'] = (target_outcomes_df['target_result'].isin({'CATCH','CATCH_AND_FUMBLE','CATCH_AND_PENALTY'})).astype(int)\n",
                "no_int_df = target_outcomes_df[target_outcomes_df['interception'] == 0].reset_index(drop=True)\n",
                "completion_outcome_df = target_outcomes_df[target_outcomes_df['completion'] == 1].reset_index(drop=True)\n",
                "completion_outcome_df['fumble_lost'] = (completion_outcome_df['target_result'] == 'CATCH_AND_FUMBLE').astype(int)\n",
                "\n",
                "comp_fumlost_df = completion_outcome_df[completion_outcome_df['fumble_lost'] == 1].reset_index(drop=True)\n",
                "comp_no_fumlost_df = completion_outcome_df[completion_outcome_df['fumble_lost'] == 0].reset_index(drop=True)\n",
                "\n",
                "comp_yards_df = (\n",
                "    comp_no_fumlost_df[comp_no_fumlost_df['touchdown'] == 0]\n",
                "    .merge(pbp[['play_id','game_id','yards_after_catch']], how='left', on=['play_id','game_id'])\n",
                "    .dropna()\n",
                ")\n",
                "\n",
                "comp_yards_df['is_positive_yac'] = (comp_yards_df['yards_after_catch'] > 0).astype(int)\n",
                "\n",
                "neg_yac_df = comp_yards_df[comp_yards_df['is_positive_yac'] == 0].reset_index(drop=True)\n",
                "pos_yac_df = comp_yards_df[comp_yards_df['is_positive_yac'] == 1].reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# target_outcomes_df.groupby(['air_yards'], as_index=False).aggregate({'completion': 'mean'}).plot(x='air_yards', y='completion', kind='scatter')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ay_cond_df = target_outcomes_df.copy().rename(columns={'wr_adot': 'adot', 'wr_xyac': 'xyac', 'wr_yac_oe': 'yac_oe'})\n",
                "ay_cond_df['is_ay_pos'] = (ay_cond_df['air_yards'] > 0).astype(int)\n",
                "\n",
                "ay_prob_features = ['zero_sigma', 'neg1_sigma', 'neg2_sigma', 'xyac', 'yac_oe']\n",
                "ay_cond_features = ['adot', 'adot_std', 'xyac', 'yac_oe']\n",
                "ay_cond_df['zero_sigma'] = norm.cdf(0, loc=ay_cond_df['adot'], scale=ay_cond_df['adot_std'])\n",
                "ay_cond_df['neg1_sigma'] = norm.cdf(0, ay_cond_df['adot'] - ay_cond_df['adot_std'], scale=ay_cond_df['adot_std'])\n",
                "ay_cond_df['neg2_sigma'] = norm.cdf(0, ay_cond_df['adot'] - 2 * ay_cond_df['adot_std'], scale=ay_cond_df['adot_std'])\n",
                "\n",
                "is_pos_ay_tgt = LogisticRegression(**LOGR_KWARGS)\n",
                "is_pos_ay_tgt.fit(ay_cond_df[ay_prob_features], ay_cond_df['is_ay_pos'])\n",
                "\n",
                "ay_neg_cond_df = ay_cond_df[ay_cond_df['is_ay_pos'] == 0].reset_index(drop=True)\n",
                "\n",
                "ay_neg_cond_mean_model = PoissonRegressor(**POIS_KWARGS)\n",
                "ay_neg_cond_mean_model.fit(ay_neg_cond_df[ay_cond_features], -1 * ay_neg_cond_df['air_yards'])\n",
                "# ay_neg_cond_mean_pred = ay_neg_cond_mean_model.predict(ay_neg_cond_df[ay_cond_features])\n",
                "# ay_neg_cond_mean_resid = (-1 * ay_neg_cond_df['air_yards'] - ay_neg_cond_mean_pred).var()\n",
                "# print(f'const AY_NEG_COND_MEAN_RESID: f32 = {ay_neg_cond_mean_resid:.4f};')\n",
                "\n",
                "ay_pos_cond_df = ay_cond_df[ay_cond_df['is_ay_pos'] == 1].reset_index(drop=True)\n",
                "prob_pos_ay_tgt = is_pos_ay_tgt.predict_proba(ay_pos_cond_df[ay_prob_features])[:,1]\n",
                "neg_cond_mean = ay_neg_cond_mean_model.predict(ay_pos_cond_df[ay_cond_features])\n",
                "pos_cond_mean = (ay_pos_cond_df['adot'] + neg_cond_mean * (1 - prob_pos_ay_tgt)) / prob_pos_ay_tgt\n",
                "\n",
                "ay_pos_cond_var_model = PoissonRegressor(**POIS_KWARGS)\n",
                "ay_pos_cond_var_model.fit(ay_pos_cond_df[ay_cond_features], (ay_pos_cond_df['air_yards'] - pos_cond_mean) ** 2)\n",
                "# ay_pos_cond_var_pred = ay_pos_cond_var_model.predict(ay_pos_cond_df[ay_cond_features])\n",
                "# ay_pos_cond_var_resid = ((ay_pos_cond_df['air_yards'] - pos_cond_mean) ** 2 - ay_pos_cond_var_pred).var()\n",
                "# print(f'const AY_POS_COND_VAR_RESID: f32 = {ay_pos_cond_var_resid:.4f};')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_is_pos_ay_tgt_model(model: LogisticRegression, name: str) -> str:\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> PositiveAirYardsTargetModel {{')\n",
                "    ret.append('        PositiveAirYardsTargetModel {')\n",
                "    ret.append(f'            intercept: {model.intercept_[0]:.4f},')\n",
                "    for f, c in zip(ay_prob_features, model.coef_[0]):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n",
                "\n",
                "def format_cond_ay_tgt_model(model: PoissonRegressor, name: str) -> str:\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> ConditionalAirYardsModel {{')\n",
                "    ret.append('        ConditionalAirYardsModel {')\n",
                "    ret.append(f'            intercept: {model.intercept_:.4f},')\n",
                "    for f, c in zip(ay_cond_features, model.coef_):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tgt_int_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_int_model.fit(target_outcomes_df[tgt_outcome_features], target_outcomes_df['interception'])\n",
                "\n",
                "tgt_int_td_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_int_td_model.fit(int_outcome_df[tgt_outcome_features], int_outcome_df['pick_six'])\n",
                "\n",
                "no_pick6 = int_outcome_df['pick_six'] == 0\n",
                "is_int_pos_yards_df = int_outcome_df[no_pick6].copy()\n",
                "is_int_pos_yards_df['is_pos_yards'] = (is_int_pos_yards_df['return_yards'] > 0).astype(int)\n",
                "\n",
                "tgt_int_yards_is_pos = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_int_yards_is_pos.fit(is_int_pos_yards_df[tgt_outcome_features], is_int_pos_yards_df['is_pos_yards'])\n",
                "\n",
                "neg_int_yards_df = is_int_pos_yards_df[is_int_pos_yards_df['is_pos_yards'] == 0].reset_index(drop=True)\n",
                "tgt_int_neg_yards_model = PoissonRegressor(**POIS_KWARGS)\n",
                "tgt_int_neg_yards_model.fit(neg_int_yards_df[tgt_outcome_features], -1 * neg_int_yards_df['return_yards'])\n",
                "# tgt_int_neg_yards_pred = tgt_int_neg_yards_model.predict(neg_int_yards_df[tgt_outcome_features])\n",
                "# tgt_int_neg_yards_resid = (-1 * neg_int_yards_df['return_yards'] - tgt_int_neg_yards_pred).var()\n",
                "# print(f'const INT_NEG_YARDS_RESID: f32 = {tgt_int_neg_yards_resid:.4f};')\n",
                "\n",
                "pos_int_yards_df = is_int_pos_yards_df[is_int_pos_yards_df['is_pos_yards'] == 1].reset_index(drop=True)\n",
                "tgt_int_pos_yards_model = PoissonRegressor(**POIS_KWARGS)\n",
                "tgt_int_pos_yards_model.fit(pos_int_yards_df[tgt_outcome_features], pos_int_yards_df['return_yards'] - 1)\n",
                "# tgt_int_pos_yards_pred = tgt_int_pos_yards_model.predict(pos_int_yards_df[tgt_outcome_features])\n",
                "# tgt_int_pos_yards_resid = (pos_int_yards_df['return_yards'] - tgt_int_pos_yards_pred).var()\n",
                "# print(f'const INT_POS_YARDS_RESID: f32 = {tgt_int_pos_yards_resid:.4f};')\n",
                "\n",
                "tgt_int_pos_mean = tgt_int_pos_yards_model.predict(pos_int_yards_df[tgt_outcome_features])\n",
                "tgt_int_pos_yards_var_model = PoissonRegressor(**POIS_KWARGS)\n",
                "tgt_int_pos_yards_var_model.fit(pos_int_yards_df[tgt_outcome_features], (pos_int_yards_df['return_yards'] - 1 - tgt_int_pos_mean) ** 2)\n",
                "# tgt_int_pos_yards_var_pred = tgt_int_pos_yards_var_model.predict(pos_int_yards_df[tgt_outcome_features])\n",
                "# tgt_int_pos_yards_var_resid = (np.log((pos_int_yards_df['return_yards'] - tgt_int_pos_mean) ** 2) - tgt_int_pos_yards_var_pred).var()\n",
                "# print(f'const INT_POS_YARDS_VAR_RESID: f32 = {tgt_int_pos_yards_var_resid:.4f};')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tgt_completion_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_completion_model.fit(no_int_df[tgt_outcome_features], no_int_df['completion'])\n",
                "\n",
                "# NOTE: if caught in the end zone, we terminate early in production\n",
                "\n",
                "# see if there's a fumble lost\n",
                "tgt_fumlost_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_fumlost_model.fit(completion_outcome_df[tgt_outcome_features], completion_outcome_df['fumble_lost'])\n",
                "\n",
                "# see if it's returned for a TD\n",
                "tgt_fumlost_td_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_fumlost_td_model.fit(comp_fumlost_df[tgt_outcome_features], comp_fumlost_df['touchdown'])\n",
                "\n",
                "# see if the catch goes for a TD\n",
                "tgt_td_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_td_model.fit(comp_no_fumlost_df[tgt_outcome_features], comp_no_fumlost_df['touchdown'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tgt_clock_runs_after_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_clock_runs_after_model.fit(comp_yards_df[tgt_outcome_features], comp_yards_df['clock_runs_after'])\n",
                "\n",
                "tgt_is_pos_yac_model = LogisticRegression(**LOGR_KWARGS)\n",
                "tgt_is_pos_yac_model.fit(comp_yards_df[yac_outcome_features], comp_yards_df['is_positive_yac'])\n",
                "\n",
                "tgt_neg_yac_model = PoissonRegressor(**POIS_KWARGS)\n",
                "tgt_neg_yac_model.fit(neg_yac_df[yac_outcome_features], -1 * neg_yac_df['yards_after_catch'])\n",
                "# tgt_neg_yac_pred = tgt_neg_yac_model.predict(neg_yac_df[yac_outcome_features])\n",
                "# tgt_neg_yac_resid = (-1 * neg_yac_df['yards_after_catch'] - tgt_neg_yac_pred).var()\n",
                "# print(f'const NEG_YAC_RESID: f32 = {tgt_neg_yac_resid:.4f};')\n",
                "\n",
                "tgt_pos_yac_model = PoissonRegressor(**POIS_KWARGS)\n",
                "tgt_pos_yac_model.fit(pos_yac_df[yac_outcome_features], pos_yac_df['yards_after_catch'] - 1)\n",
                "tgt_pos_yac_mean = tgt_pos_yac_model.predict(pos_yac_df[yac_outcome_features])\n",
                "# tgt_pos_yac_resid = (pos_yac_df['yards_after_catch'] - tgt_pos_yac_mean).var()\n",
                "# print(f'const POS_YAC_RESID: f32 = {tgt_pos_yac_resid:.4f};')\n",
                "\n",
                "tgt_pos_yac_var_model = PoissonRegressor(**POIS_KWARGS)\n",
                "tgt_pos_yac_var_model.fit(pos_yac_df[yac_outcome_features], (pos_yac_df['yards_after_catch'] - 1 - tgt_pos_yac_mean) ** 2)\n",
                "# tgt_pos_yac_var_pred = tgt_pos_yac_var_model.predict(pos_yac_df[yac_outcome_features])\n",
                "# tgt_pos_yac_var_resid = ((pos_yac_df['yards_after_catch'] - tgt_pos_yac_mean) ** 2 - tgt_pos_yac_var_pred).var()\n",
                "# print(f'const POS_YAC_VAR_RESID: f32 = {tgt_pos_yac_var_resid:.4f};')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_ay_linr_model(model_: PoissonRegressor, name: str):\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> AirYardsModel {{')\n",
                "    ret.append('        AirYardsModel {')\n",
                "    ret.append(f'            intercept: {model_.intercept_:.4f},')\n",
                "    for f, c in zip(prod_airyards_features, model_.coef_):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n",
                "\n",
                "def format_ay_logr_model(model_: LogisticRegression, name: str):\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> AirYardsModel {{')\n",
                "    ret.append('        AirYardsModel {')\n",
                "    ret.append(f'            intercept: {model_.intercept_[0]:.4f},')\n",
                "    for f, c in zip(prod_airyards_features, model_.coef_[0]):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n",
                "\n",
                "def format_tgt_logr_model(model_: LogisticRegression, name: str):\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> TargetModel {{')\n",
                "    ret.append('        TargetModel {')\n",
                "    ret.append(f'            intercept: {model_.intercept_[0]:.4f},')\n",
                "    for f, c in zip(yac_outcome_features, model_.coef_[0]):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    for f in yac_outcome_features[model_.coef_[0].size:]:\n",
                "        ret.append(f'            {f}: 0.0,')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)\n",
                "\n",
                "def format_tgt_linr_model(model_: PoissonRegressor, name: str):\n",
                "    ret = []\n",
                "    ret.append(f'\\n    pub fn {name}_coef() -> TargetModel {{')\n",
                "    ret.append('        TargetModel {')\n",
                "    ret.append(f'            intercept: {model_.intercept_:.4f},')\n",
                "    for f, c in zip(yac_outcome_features, model_.coef_):\n",
                "        ret.append(f'            {f}: {c:.4f},')\n",
                "    for f in yac_outcome_features[model_.coef_.size:]:\n",
                "        ret.append(f'            {f}: 0.0,')\n",
                "    ret.append('        }')\n",
                "    ret.append('    }\\n')\n",
                "    return '\\n'.join(ret)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(\"pub struct AirYardsModel {\")\n",
                "# print(\"    intercept: f32,\")\n",
                "# for f in prod_airyards_features:\n",
                "#     print(f'    {f}: f32,')\n",
                "# print(\"}\")\n",
                "\n",
                "# print(\"pub struct TargetModel {\")\n",
                "# print(\"    intercept: f32,\")\n",
                "# for f in prod_target_features:\n",
                "#     print(f'    {f}: f32,')\n",
                "# print(\"}\")\n",
                "\n",
                "# print(\"pub struct PositiveAirYardsTargetModel {\")\n",
                "# print(\"    intercept: f32,\")\n",
                "# for f in ay_prob_features:\n",
                "#     print(f'    {f}: f32,')\n",
                "# print(\"}\")\n",
                "\n",
                "# print(\"pub struct ConditionalAirYardsModel\")\n",
                "# print(\"    intercept: f32,\")\n",
                "# for f in ay_cond_features:\n",
                "#     print(f'    {f}: f32,')\n",
                "# print(\"}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ay_model_str_parts = [\"use crate::models::air_yards::AirYardsModel;\\n\", \"impl AirYardsModel {\"]\n",
                "\n",
                "ay_model_str_parts.append(format_ay_logr_model(is_pos_air_yards_model, 'is_pos_air_yards'))\n",
                "ay_model_str_parts.append(format_ay_linr_model(neg_air_yards_model, 'neg_air_yards'))\n",
                "ay_model_str_parts.append(format_ay_linr_model(pos_air_yards_model, 'pos_air_yards'))\n",
                "ay_model_str_parts.append(format_ay_linr_model(pos_air_yards_var_model, 'pos_air_yards_var'))\n",
                "ay_model_str_parts.append(\"}\")\n",
                "\n",
                "ay_model_str = '\\n'.join(ay_model_str_parts)\n",
                "\n",
                "with open(f'{MODELS_PATH}/air_yards/coef.rs', 'w') as f:\n",
                "    f.write(ay_model_str)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tgt_model_str_parts = [\"use crate::models::targets::{TargetModel, ConditionalAirYardsModel, PositiveAirYardsTargetModel};\\n\"]\n",
                "\n",
                "tgt_model_str_parts.append(\"impl TargetModel {\")\n",
                "# interception? if so, predict pick 6 or return yards distribution\n",
                "tgt_model_str_parts.append(format_tgt_logr_model(tgt_int_model, 'prob_int'))\n",
                "tgt_model_str_parts.append(format_tgt_logr_model(tgt_int_td_model, 'prob_pick_six'))\n",
                "tgt_model_str_parts.append(format_tgt_logr_model(tgt_int_yards_is_pos, 'is_int_return_yards_pos'))\n",
                "tgt_model_str_parts.append(format_tgt_linr_model(tgt_int_neg_yards_model, 'int_neg_return_yards'))\n",
                "tgt_model_str_parts.append(format_tgt_linr_model(tgt_int_pos_yards_model, 'int_pos_return_yards'))\n",
                "tgt_model_str_parts.append(format_tgt_linr_model(tgt_int_pos_yards_var_model, 'int_pos_return_yards_var'))\n",
                "# completion? if so, predict result\n",
                "tgt_model_str_parts.append(format_tgt_logr_model(tgt_completion_model, 'prob_completion'))\n",
                "# assume this is 0 in production. so rarely happens...\n",
                "# tgt_model_str_parts.append(format_tgt_logr_model(tgt_fumlost_model, 'prob_catch_fumble_lost'))\n",
                "# tgt_model_str_parts.append(format_tgt_logr_model(tgt_fumlost_td_model, 'prob_catch_fumble_lost_td'))\n",
                "tgt_model_str_parts.append(format_tgt_logr_model(tgt_td_model, 'prob_catch_td'))\n",
                "\n",
                "tgt_model_str_parts.append(format_tgt_logr_model(tgt_clock_runs_after_model, 'clock_runs_after'))\n",
                "tgt_model_str_parts.append(format_tgt_logr_model(tgt_is_pos_yac_model, 'is_pos_yac'))\n",
                "tgt_model_str_parts.append(format_tgt_linr_model(tgt_neg_yac_model, 'neg_yac'))\n",
                "tgt_model_str_parts.append(format_tgt_linr_model(tgt_pos_yac_model, 'pos_yac'))\n",
                "tgt_model_str_parts.append(format_tgt_linr_model(tgt_pos_yac_var_model, 'pos_yac_var'))\n",
                "tgt_model_str_parts.append(\"}\")\n",
                "\n",
                "tgt_model_str_parts.append(\"impl PositiveAirYardsTargetModel {\")\n",
                "tgt_model_str_parts.append(format_is_pos_ay_tgt_model(is_pos_ay_tgt, 'is_positive_ay_target'))\n",
                "tgt_model_str_parts.append(\"}\")\n",
                "\n",
                "tgt_model_str_parts.append(\"impl ConditionalAirYardsModel {\")\n",
                "tgt_model_str_parts.append(format_cond_ay_tgt_model(ay_neg_cond_mean_model, 'neg_ay_target_mean'))\n",
                "tgt_model_str_parts.append(format_cond_ay_tgt_model(ay_pos_cond_var_model, 'pos_ay_target_variance'))\n",
                "tgt_model_str_parts.append(\"}\")\n",
                "\n",
                "tgt_model_str = '\\n'.join(tgt_model_str_parts)\n",
                "\n",
                "with open(f'{MODELS_PATH}/targets/coef.rs', 'w') as f:\n",
                "    f.write(tgt_model_str)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def weight_team_features(season: int) -> float:\n",
                "    if season < CURRENT_SEASON - 2:\n",
                "        return 0\n",
                "    if season == CURRENT_SEASON:\n",
                "        return 1.0\n",
                "    if season == CURRENT_SEASON - 1:\n",
                "        return 0.5\n",
                "    if season == CURRENT_SEASON - 2:\n",
                "        return 0.1\n",
                "    return 0.0\n",
                "\n",
                "def season_weight_decay(decay: float, cutoff_delta: int = 10):\n",
                "    def _inner(season: int):\n",
                "        if season + cutoff_delta < CURRENT_SEASON:\n",
                "            return 0.0\n",
                "        return math.exp(decay * (season - CURRENT_SEASON))\n",
                "    return _inner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_games = (\n",
                "    pbp\n",
                "    .groupby(['season','posteam'], as_index=False)\n",
                "    .aggregate({'game_id': 'nunique'})\n",
                "    .rename(columns={'game_id': 'n_games', 'posteam': 'team'})\n",
                ")\n",
                "\n",
                "proj_team_df = (\n",
                "    n_games\n",
                "    .merge(team_completion_features, on=['season','team'])\n",
                "    .merge(joined_line_features, on=['season','team'])\n",
                "    .merge(def_yac_oe_df, on=['season','team'])\n",
                ")\n",
                "\n",
                "proj_team_df['weight'] = proj_team_df['n_games'] * proj_team_df['season'].apply(season_weight_decay(1.0))\n",
                "tm_ft_cols = ['offense_pass_rush_z','defense_pass_rush_z','def_comp_z','def_int_z', 'def_yac_oe']\n",
                "for c in tm_ft_cols:\n",
                "    proj_team_df[c] = proj_team_df[c] * proj_team_df['weight']\n",
                "\n",
                "proj_team_features_df = (\n",
                "    proj_team_df\n",
                "    .groupby(['team'], as_index=False)\n",
                "    .aggregate({\n",
                "        'weight': 'sum',\n",
                "        **{c: 'sum' for c in tm_ft_cols},\n",
                "    })\n",
                "    .sort_values('weight', ascending=False)\n",
                ")\n",
                "for c in tm_ft_cols:\n",
                "    proj_team_features_df[c] = (proj_team_features_df[c] / proj_team_features_df['weight']).round(decimals=2)\n",
                "\n",
                "proj_team_features_df.drop(columns=['weight'], inplace=True)\n",
                "proj_team_features_df.rename(inplace=True, columns={'def_comp_z': 'defense_completion_z', 'def_int_z': 'defense_interception_z', 'def_yac_oe': 'defense_yac_oe'})\n",
                "\n",
                "proj_team_features_df.to_csv(f'{BASELINES_PATH}/team_dropbacks.csv', index=False)\n",
                "proj_team_features_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "proj_team_features_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preproj_qb_features = qb_features_df.merge(qb_sack_avoidance, on=['passer_id','season'])\n",
                "preproj_qb_features['airyards_weight'] = preproj_qb_features['count'] * preproj_qb_features['season'].apply(season_weight_decay(0.8))\n",
                "preproj_qb_features['accuracy_weight'] = preproj_qb_features['count'] * preproj_qb_features['season'].apply(season_weight_decay(1.0))\n",
                "\n",
                "preproj_qb_features['comp_oe_wt'] = preproj_qb_features['accuracy_weight'] * preproj_qb_features['comp_oe']\n",
                "preproj_qb_features['int_ue_wt'] = preproj_qb_features['accuracy_weight'] * preproj_qb_features['int_ue']\n",
                "\n",
                "preproj_qb_features['air_yards_oe_wt'] = preproj_qb_features['airyards_weight'] * preproj_qb_features['ay_oe']\n",
                "preproj_qb_features['air_yards_var_wt'] = preproj_qb_features['airyards_weight'] * preproj_qb_features['ay_std'] ** 2\n",
                "\n",
                "preproj_qb_features['qb_prob_sack_given_hit_wt'] = preproj_qb_features['accuracy_weight'] * preproj_qb_features['qb_prob_sack_given_hit']\n",
                "\n",
                "qb_projections = (\n",
                "    preproj_qb_features\n",
                "    .groupby(['passer_id'], as_index=False)\n",
                "    .aggregate({\n",
                "        'airyards_weight': 'sum',\n",
                "        'accuracy_weight': 'sum',\n",
                "        'comp_oe_wt': 'sum',\n",
                "        'int_ue_wt': 'sum',\n",
                "        'air_yards_oe_wt': 'sum',\n",
                "        'air_yards_var_wt': 'sum',\n",
                "        'qb_prob_sack_given_hit_wt': 'sum',\n",
                "        'count': 'sum',\n",
                "    })\n",
                ")\n",
                "qb_projections['comp_oe'] = (qb_projections['comp_oe_wt'] / qb_projections['accuracy_weight']).round(decimals=3)\n",
                "qb_projections['int_ue'] = (qb_projections['int_ue_wt'] / qb_projections['accuracy_weight']).round(decimals=3)\n",
                "\n",
                "qb_projections['ayoe'] = (qb_projections['air_yards_oe_wt'] / qb_projections['airyards_weight']).round(decimals=1)\n",
                "qb_projections['ay_std'] = (np.sqrt(qb_projections['air_yards_var_wt'] / qb_projections['airyards_weight'])).round(decimals=1)\n",
                "qb_projections['prob_sack_given_hit'] = (qb_projections['qb_prob_sack_given_hit_wt'] / qb_projections['accuracy_weight']).round(decimals=2)\n",
                "\n",
                "qbpr_df = (\n",
                "    qb_projections\n",
                "    .rename(columns={'comp_oe': 'cpoe', 'passer_id': 'player_id'})\n",
                "    .drop(columns=['airyards_weight', 'accuracy_weight', 'comp_oe_wt', 'int_ue_wt', 'air_yards_oe_wt', 'air_yards_var_wt', 'qb_prob_sack_given_hit_wt', 'count'])\n",
                ")\n",
                "# TODO: target shares\n",
                "write_qb_projs = (\n",
                "    rosters[['player_id','team']]\n",
                "    .merge(player_names, on=['player_id'], how='inner')\n",
                "    .merge(qbpr_df, on=['player_id'], how='inner')\n",
                "    .sort_values('team', ascending=True)\n",
                ")\n",
                "\n",
                "write_qb_projs.to_csv(f'{BASELINES_PATH}/qbs.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# so guys who have 0 targets this year count as 0\n",
                "each_teams_games = (\n",
                "    target_df[target_df['season'] == CURRENT_SEASON]\n",
                "    .groupby(['season','posteam'], as_index=False)\n",
                "    .aggregate({'game_id': 'nunique'})\n",
                "    .rename(columns={'posteam': 'team', 'game_id': 'n_games'})\n",
                ")\n",
                "this_season_fake = rosters[['player_id','team']].merge(each_teams_games, on=['team'])\n",
                "this_season_fake['season'] = CURRENT_SEASON\n",
                "this_season_fake['targets'] = 0\n",
                "this_season_fake['is_redzone'] = 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CURRENT_SEASON_ZERO_MULT = 0.5\n",
                "DISPERSION_COEF = 1.0\n",
                "PRIOR_TARGETS = 20\n",
                "\n",
                "team_tgt_sums = (\n",
                "    target_df\n",
                "    .groupby(['season','posteam'], as_index=False)\n",
                "    .aggregate({'play_id': 'count'})\n",
                "    .rename(columns={'play_id': 'team_targets', 'posteam': 'team'})\n",
                ")\n",
                "\n",
                "target_df['is_redzone'] = (target_df['yardline_100'] <= 20).astype(int)\n",
                "prior_rz = target_df['is_redzone'].mean()\n",
                "prev_target_counts = (\n",
                "    target_df\n",
                "    .groupby(['season','posteam','receiver_id'], as_index=False)\n",
                "    .aggregate({'is_redzone': 'sum', 'play_id': 'count', 'game_id': 'nunique'})\n",
                "    .rename(columns={\n",
                "        'play_id': 'targets',\n",
                "        'posteam': 'team',\n",
                "        'receiver_id': 'player_id',\n",
                "        'game_id': 'n_games',\n",
                "    })\n",
                ")\n",
                "\n",
                "adj_target_counts = (\n",
                "    pd.concat([prev_target_counts, this_season_fake])\n",
                "    .drop_duplicates(subset=['season','team','player_id'], keep='first')\n",
                ")\n",
                "\n",
                "ts_groups = adj_target_counts.merge(team_tgt_sums, on=['season','team'])\n",
                "ts_groups['ms_targets'] = ts_groups['targets'] / ts_groups['team_targets']\n",
                "ts_groups['prob_rz_given_target'] = (prior_rz * PRIOR_TARGETS + ts_groups['is_redzone']) / (ts_groups['targets'] + PRIOR_TARGETS)\n",
                "ts_groups['season_weight'] = ts_groups['n_games'] * ts_groups['season'].apply(season_weight_decay(1.2, 4))\n",
                "ts_groups['weighted_ms_targets'] = ts_groups['ms_targets'] * ts_groups['season_weight']\n",
                "ts_groups['weighted_prob_rz_given_target'] = ts_groups['prob_rz_given_target'] * ts_groups['season_weight']\n",
                "\n",
                "zero_this_year = ts_groups[(ts_groups['season'] == CURRENT_SEASON) & (ts_groups['ms_targets'] == 0)][['player_id']]\n",
                "zero_this_year['current_season_zero'] = 1.0\n",
                "\n",
                "proj_raw_shares = (\n",
                "    ts_groups\n",
                "    .groupby(['player_id',], as_index=False)\n",
                "    .aggregate({\n",
                "        'weighted_prob_rz_given_target': 'sum',\n",
                "        'weighted_ms_targets': 'sum',\n",
                "        'season_weight': 'sum',\n",
                "    })\n",
                "    .merge(zero_this_year, on=['player_id'], how='left')\n",
                "    .fillna({'current_season_zero': 0.0})\n",
                ")\n",
                "\n",
                "proj_raw_shares['ms_targets'] = proj_raw_shares['weighted_ms_targets'] / proj_raw_shares['season_weight']\n",
                "proj_raw_shares['prob_rz_given_target'] = proj_raw_shares['weighted_prob_rz_given_target'] / proj_raw_shares['season_weight']\n",
                "proj_raw_shares.loc[proj_raw_shares['current_season_zero'] == 1, 'ms_targets'] *= CURRENT_SEASON_ZERO_MULT\n",
                "proj_raw_shares.drop(inplace=True, columns=[\n",
                "    'weighted_prob_rz_given_target',\n",
                "    'weighted_ms_targets',\n",
                "    'season_weight',\n",
                "])\n",
                "\n",
                "roster_shares = rosters[['player_id','team']].merge(proj_raw_shares, on=['player_id'], how='inner')\n",
                "team_denoms_disp = roster_shares.groupby(['team'], as_index=False).aggregate({'ms_targets': 'sum'}).rename(columns={'ms_targets': 'team_ms_sum'})\n",
                "\n",
                "dpns = roster_shares.merge(team_denoms_disp, on=['team'], how='left')\n",
                "dpns['ms_targets'] = dpns['ms_targets'] ** (DISPERSION_COEF * dpns['team_ms_sum'])\n",
                "\n",
                "team_denoms = (\n",
                "    dpns\n",
                "    .groupby(['team'], as_index=False)\n",
                "    .aggregate({'ms_targets': 'sum'})\n",
                "    .rename(columns={'ms_targets': 'team_ms_sum'})\n",
                ")\n",
                "\n",
                "proj_normed_shares = (\n",
                "    dpns\n",
                "    .drop(columns=['current_season_zero','team_ms_sum'])\n",
                "    .merge(team_denoms, on=['team'], how='left')\n",
                "    .sort_values(['team', 'ms_targets'], ascending=[True, False])\n",
                ")\n",
                "proj_normed_shares['ms_targets'] /= proj_normed_shares['team_ms_sum']\n",
                "proj_normed_shares['ms_targets'] = proj_normed_shares['ms_targets'].round(decimals=3)\n",
                "proj_normed_shares['prob_rz_given_target'] = proj_normed_shares['prob_rz_given_target'].round(decimals=3)\n",
                "proj_normed_shares.drop(columns=['team_ms_sum'], inplace=True)\n",
                "# proj_normed_shares.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preproj_wr_features = wr_features.copy()\n",
                "\n",
                "preproj_wr_features['adot_weight'] = preproj_wr_features['targets'] * preproj_wr_features['season'].apply(season_weight_decay(1.0))\n",
                "preproj_wr_features['catches_weight'] = preproj_wr_features['catches'] * preproj_wr_features['season'].apply(season_weight_decay(0.8))\n",
                "preproj_wr_features['target_weight'] = preproj_wr_features['targets'] * preproj_wr_features['season'].apply(season_weight_decay(0.8))\n",
                "\n",
                "preproj_wr_features['xyac_wt'] = preproj_wr_features['target_weight'] * preproj_wr_features['xyac']\n",
                "preproj_wr_features['yac_oe_wt'] = preproj_wr_features['catches_weight'] * preproj_wr_features['yac_oe']\n",
                "preproj_wr_features['catch_oe_wt'] = preproj_wr_features['target_weight'] * preproj_wr_features['catch_oe']\n",
                "preproj_wr_features['adot_wt'] = preproj_wr_features['adot_weight'] * preproj_wr_features['adot']\n",
                "preproj_wr_features['adot_var_wt'] = preproj_wr_features['adot_weight'] * preproj_wr_features['adot_std'] ** 2\n",
                "\n",
                "wr_projections = (\n",
                "    preproj_wr_features\n",
                "    .groupby(['player_id'], as_index=False)\n",
                "    .aggregate({\n",
                "        'adot_weight': 'sum',\n",
                "        'catches_weight': 'sum',\n",
                "        'target_weight': 'sum',\n",
                "        'xyac_wt': 'sum',\n",
                "        'yac_oe_wt': 'sum',\n",
                "        'catch_oe_wt': 'sum',\n",
                "        'adot_wt': 'sum',\n",
                "        'adot_var_wt': 'sum',\n",
                "        'targets': 'sum',\n",
                "        'catches': 'sum',\n",
                "    })\n",
                ")\n",
                "\n",
                "wr_projections['xyac'] = (wr_projections['xyac_wt'] / wr_projections['target_weight']).round(decimals=2)\n",
                "wr_projections['yac_oe'] = (wr_projections['yac_oe_wt'] / wr_projections['catches_weight']).round(decimals=2)\n",
                "wr_projections['prob_catch_oe'] = (wr_projections['catch_oe_wt'] / wr_projections['target_weight']).round(decimals=2)\n",
                "wr_projections['adot'] = (wr_projections['adot_wt'] / wr_projections['adot_weight']).round(decimals=1)\n",
                "wr_projections['adot_std'] = (np.sqrt(wr_projections['adot_var_wt'] / wr_projections['adot_weight'])).round(decimals=1)\n",
                "\n",
                "wrsk_df = (\n",
                "    wr_projections\n",
                "    .rename(columns={'receiver_id': 'player_id'})\n",
                "    .drop(columns=[\n",
                "        'adot_weight','catches_weight','target_weight',\n",
                "        'xyac_wt', 'yac_oe_wt','catch_oe_wt','adot_wt','adot_var_wt', 'catches'\n",
                "    ])\n",
                ")\n",
                "\n",
                "write_wr_projs = (\n",
                "    rosters[['player_id','team']]\n",
                "    .merge(player_names, on=['player_id'], how='inner')\n",
                "    .merge(proj_normed_shares, on=['player_id','team'], how='inner')\n",
                "    .merge(wrsk_df, on=['player_id'], how='inner')\n",
                "    .sort_values(['team', 'position'], ascending=True)\n",
                "    [['player_id','team','name','position','ms_targets','prob_rz_given_target','prob_catch_oe','adot', 'adot_std', 'xyac', 'yac_oe', 'targets']]\n",
                ")\n",
                "\n",
                "write_wr_projs.to_csv(f'{BASELINES_PATH}/pass_catchers.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "write_wr_projs.sort_values('ms_targets', ascending=False).head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
